{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System\n",
    "\n",
    "### What this project does\n",
    "### What this project doesn't do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now, I've encountered two types of data objects in the Pandas library—DataFrames and Series, and here is a [Scaler Topics article on core components of Pandas](https://www.scaler.com/topics/pandas/core-components-of-pandas/), confirming that these two are the important ones (for single-dimensional, and two-dimensional data respectively), apart from a third object type, `Panel` (for three-dimensional data).\n",
    "\n",
    "Here's a micro-article attempting to list the organisation of files in Pandas' architecture: [Discover Pandas Library Architecture – File Hierarchy in Pandas](https://data-flair.training/blogs/pandas-library-architecture/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.read_csv(\"./ml-latest-small/ratings.csv\")\n",
    "# ratings_df = pd.read_csv(\"./anime-ratings-matrix-factorization-v-10/anime ratings dataset/rating.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100836 entries, 0 to 100835\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   userId     100836 non-null  int64  \n",
      " 1   movieId    100836 non-null  int64  \n",
      " 2   rating     100836 non-null  float64\n",
      " 3   timestamp  100836 non-null  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "ratings_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9724 movies and 610 users in the dataset\n"
     ]
    }
   ],
   "source": [
    "# num_movies = pd.DataFrame(ratings_df['movieId'].unique()).count().values[0]       #this is a tad more convoluted way\n",
    "# num_users = pd.DataFrame(ratings_df['userId'].unique()).count().values[0]\n",
    "num_movies = ratings_df['movieId'].unique().shape[0]                                #better way\n",
    "num_users = ratings_df['userId'].unique().shape[0]\n",
    "print(f\"There are {num_movies} movies and {num_users} users in the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 user IDs exceeding 610.\n",
      "There are 4334 movie IDs exceeding 9724.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {ratings_df.loc[ratings_df.userId > 610].shape[0]} user IDs exceeding 610.\")\n",
    "print(f\"There are {ratings_df.loc[ratings_df.movieId > 9724].movieId.unique().shape[0]} movie IDs exceeding 9724.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the user IDs are contiguous, while the move IDs are not. We might have to consider making them contiguous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <td>100836.0</td>\n",
       "      <td>3.261276e+02</td>\n",
       "      <td>1.826185e+02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.770000e+02</td>\n",
       "      <td>3.250000e+02</td>\n",
       "      <td>4.770000e+02</td>\n",
       "      <td>6.100000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <td>100836.0</td>\n",
       "      <td>1.943530e+04</td>\n",
       "      <td>3.553099e+04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.199000e+03</td>\n",
       "      <td>2.991000e+03</td>\n",
       "      <td>8.122000e+03</td>\n",
       "      <td>1.936090e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <td>100836.0</td>\n",
       "      <td>3.501557e+00</td>\n",
       "      <td>1.042529e+00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.500000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <td>100836.0</td>\n",
       "      <td>1.205946e+09</td>\n",
       "      <td>2.162610e+08</td>\n",
       "      <td>828124615.0</td>\n",
       "      <td>1.019124e+09</td>\n",
       "      <td>1.186087e+09</td>\n",
       "      <td>1.435994e+09</td>\n",
       "      <td>1.537799e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count          mean           std          min           25%  \\\n",
       "userId     100836.0  3.261276e+02  1.826185e+02          1.0  1.770000e+02   \n",
       "movieId    100836.0  1.943530e+04  3.553099e+04          1.0  1.199000e+03   \n",
       "rating     100836.0  3.501557e+00  1.042529e+00          0.5  3.000000e+00   \n",
       "timestamp  100836.0  1.205946e+09  2.162610e+08  828124615.0  1.019124e+09   \n",
       "\n",
       "                    50%           75%           max  \n",
       "userId     3.250000e+02  4.770000e+02  6.100000e+02  \n",
       "movieId    2.991000e+03  8.122000e+03  1.936090e+05  \n",
       "rating     3.500000e+00  4.000000e+00  5.000000e+00  \n",
       "timestamp  1.186087e+09  1.435994e+09  1.537799e+09  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rating</th>\n",
       "      <th>4.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>3.5</th>\n",
       "      <th>4.5</th>\n",
       "      <th>2.0</th>\n",
       "      <th>2.5</th>\n",
       "      <th>1.0</th>\n",
       "      <th>1.5</th>\n",
       "      <th>0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26818</td>\n",
       "      <td>20047</td>\n",
       "      <td>13211</td>\n",
       "      <td>13136</td>\n",
       "      <td>8551</td>\n",
       "      <td>7551</td>\n",
       "      <td>5550</td>\n",
       "      <td>2811</td>\n",
       "      <td>1791</td>\n",
       "      <td>1370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rating    4.0    3.0    5.0    3.5   4.5   2.0   2.5   1.0   1.5   0.5\n",
       "count   26818  20047  13211  13136  8551  7551  5550  2811  1791  1370"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series.value_counts(ratings_df['rating']).to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(ratings_df['rating'], bins=[(i-1)/2 for i in range(0, 12)])\n",
    "# plt.hist(ratings_df['rating'], bins=[i-0.5 for i in range(-1,12)])  #for anime ratings dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId       0\n",
      "movieId      0\n",
      "rating       0\n",
      "timestamp    0\n",
      "dtype: int64 \n",
      "\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print( ratings_df.isna().sum() , \"\\n\")\n",
    "print( type(ratings_df.isna().sum()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100836"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( len(ratings_df.duplicated(subset=['userId', 'movieId'])) )\n",
    "len(np.where( ratings_df.duplicated(subset=['userId', 'movieId']) == False )[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There don't seem to be any duplicates *shruggie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 2.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy = np.zeros((3,4))\n",
    "toy[0,1] = 1\n",
    "toy[2,3] = 2\n",
    "toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2.]\n",
      "2\n",
      "(array([0, 2], dtype=int32), array([1, 3], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "toy_csc = sparse.csc_matrix(toy)\n",
    "print( toy_csc.data )\n",
    "print( toy_csc.nnz )  # nnz => no. of non-zero (entries)\n",
    "print( toy_csc.nonzero() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 4.]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_csc.power(2).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating  timestamp  movieNewId\n",
      "0       1        1     4.0  964982703           0\n",
      "1       1        3     4.0  964981247           1\n",
      "2       1        6     4.0  964982224           2\n",
      "3       1       47     5.0  964983815           3\n",
      "4       1       50     5.0  964982931           4 \n",
      "\n",
      "       movieId  movieNewId\n",
      "17007      156        4463\n",
      "96137      156        4463\n",
      "97391      156        4463 \n",
      "\n",
      "There are 9724 movies and correspondingly 9724.0 contiguous movie IDs now\n"
     ]
    }
   ],
   "source": [
    "movie_old_new_id = np.zeros(ratings_df[\"movieId\"].max()+1)\n",
    "for new_id, old_id in enumerate(ratings_df['movieId'].unique()):\n",
    "       movie_old_new_id[old_id] = new_id\n",
    "       \n",
    "ratings_df['movieNewId'] = movie_old_new_id[ratings_df['movieId']]\n",
    "ratings_df = ratings_df.astype({'movieNewId': 'int64'})\n",
    "print( ratings_df.head(), \"\\n\" )\n",
    "\n",
    "# now just to check that we did it correctly, a movieId should be mapped to the same movieNewId\n",
    "print( ratings_df.loc[ratings_df.movieId == 156][['movieId', 'movieNewId']], \"\\n\" ) \n",
    "print(f\"There are {num_movies} movies and correspondingly {max(movie_old_new_id)+1} contiguous movie IDs now\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       userId  movieId  rating   timestamp  movieNewId\n",
      "0          64     3101     3.5  1161521521        1685\n",
      "1         354     1997     4.0  1200952925        2904\n",
      "2         564    74946     4.0  1478451898        3471\n",
      "3         608       44     0.5  1117504562         971\n",
      "4          66     4149     4.0  1113190565        3237\n",
      "...       ...      ...     ...         ...         ...\n",
      "80663      28    39381     3.5  1234338567        2294\n",
      "80664     605      314     3.0  1277176056         595\n",
      "80665      89     1394     2.0  1520408298        1474\n",
      "80666      30    59315     5.0  1500370444        1054\n",
      "80667      64     1204     5.0  1161529352        2395\n",
      "\n",
      "[80668 rows x 5 columns]\n",
      "       userId  movieId  rating   timestamp  movieNewId\n",
      "0         409     1125     3.0   967920162        2997\n",
      "1          47       31     3.0  1496205717         259\n",
      "2         401     4306     3.5  1514347054         744\n",
      "3         473     5785     3.5  1169351797        1850\n",
      "4         200      357     4.0  1229886985         313\n",
      "...       ...      ...     ...         ...         ...\n",
      "20163     239     2141     4.0  1221147497         138\n",
      "20164     221      953     5.0  1111178205        2394\n",
      "20165      68      110     2.5  1158531496           7\n",
      "20166     290     1186     4.0   975030982        1100\n",
      "20167      81      150     3.0   845299424         463\n",
      "\n",
      "[20168 rows x 5 columns]\n",
      "(80668, 5) (20168, 5)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(ratings_df, test_size=0.2)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "print(train_df)\n",
    "print(test_df)\n",
    "print( np.shape(train_df), np.shape(test_df) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we've chosen to make the movie IDs contiguous by mapping them to new ones, splitting the DataFrame makes creating smaller-dimensional matrix representations of the training or test sets difficult, because, say, the indices chosen in the training set can still lie out of bounds of its smaller matrix's size (similar logic holds for the test set).\n",
    "\n",
    "Instead, let's just work with the full ratings matrix, with the test entries zeroed out in the training matrix (and vice versa), which wouldn't be a bother to the memory anyway because we're using a sparse representation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 80668 & 20168 non-zero elements in the train and test sparse matrices respectively.\n",
      " 611 9725\n"
     ]
    }
   ],
   "source": [
    "train = sparse.csc_matrix( (train_df['rating'].values, (train_df['userId'].values, train_df['movieNewId'].values)),\\\n",
    "                                 shape=(num_users+1, num_movies+1) )\n",
    "test = sparse.csc_matrix(  (test_df['rating'].values, (test_df['userId'].values, test_df['movieNewId'].values)),\\\n",
    "                                 shape=(num_users+1, num_movies+1))\n",
    "\n",
    "print(f\"There are {train.nnz} & {test.nnz} non-zero elements in the train and test sparse matrices respectively.\\n\", test.shape[0],train.shape[1] )\n",
    "# train.to_dense()\n",
    "# print( train )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemme check once that the test and train matrix elements are indeed mutually exclusive (zero, non-zero in their matrices respectively).\n",
    "\n",
    "The cell below seems to show all's good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.shape( test.nonzero() )\n",
    "# print( test.nonzero() )\n",
    "for i in zip(test.nonzero()[0], test.nonzero()[1]):\n",
    "       if( train[i[0],i[1]] != 0 ):\n",
    "              print(\"Hah!\")\n",
    "for i in zip(train.nonzero()[0], train.nonzero()[1]):\n",
    "       if( test[i[0],i[1]] != 0 ):\n",
    "              print(\"Hah!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   1   1 ... 610 610 610]\n",
      "[  1   1   1 ... 610 610 610] \n",
      "\n",
      "[   0    0    0 ... 9720 9721 9723]\n",
      "[   0    0    0 ... 9720 9721 9723]\n",
      "[ True  True  True ...  True  True  True]\n",
      "[ True  True  True ...  True  True  True] \n",
      "\n",
      "(array([], dtype=int64),)\n",
      "(array([], dtype=int64),)\n",
      "(array([], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "print( np.sort(train_df['userId'].values) )\n",
    "print( mf.p_nnz_idx, \"\\n\" )\n",
    "\n",
    "print( np.sort(train_df['movieNewId'].values) )\n",
    "print( np.sort(mf.q_nnz_idx ) )\n",
    "print( np.sort(train_df['userId'].values) == mf.p_nnz_idx )\n",
    "print( np.sort(train_df['movieNewId'].values) == np.sort(mf.q_nnz_idx), \"\\n\" )\n",
    "\n",
    "print( np.where( np.sort(train_df['userId'].values) != train.nonzero()[0]) )\n",
    "print( np.where( np.sort(train_df['movieNewId'].values) != np.sort( train.nonzero()[1]) ) )\n",
    "print( np.where( np.sort(train_df['movieNewId'].values) != np.sort(mf.q_nnz_idx)) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm, so the row indices seem to be all good, ~~but the column indices are playing foul.~~ as do the column indices.\n",
    "\n",
    "Wasted quite the time pursuing this!\n",
    "\n",
    "We have used the list `train_df['movieNewId'].values` as the column indices needed to generate R, but upon querying back these column indices, they're coming out wrong!\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorisation Class\n",
    "Below, I furnish a Matrix Factorisation Python class that implements:\n",
    "- gradient descent\n",
    "- (pending) sgd\n",
    "- (pending) ALS\n",
    "to learn the embeddings.\n",
    "\n",
    "My current implementation of gradient descent considers the loss function for explicit ratings, i.e. solely over observed values.\n",
    "Still need to implement the Koren et al. approach capturing implicit ratings from the entire matrix.\n",
    "\n",
    "The regularised loss I've used for explicit ratings: $L(R, P, Q) = \\underset{(i,j):r_{ui}≠Nan}{\\sum} (r_{ui} - p_u^T\\cdot q_i)^2 + \\lambda(\\sum_u{||p_u||^2} + \\sum_i{||q_i||^2})$\n",
    "It's a squared error (SE) loss function with regularisation terms. I wonder how using the Mean SE or RMSE would change the behaviour. Conceptually, it shouldn't..\n",
    "\n",
    "The matrix product used to calculate the prediction for the error term in the gradient can be further optimised, as done in the other notebook, but for now, I'm just gonna roll with a matrix product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorisation():\n",
    "       def __init__(self, R: sparse.csc_matrix, k: int):\n",
    "              self.R = R           # R is the \"ratings\" matrix to be factorised\n",
    "              self.k = k           # hyperparameter k is the number of latent factors desired in the factorised embeddings\n",
    "              self.m, self.n = R.shape\n",
    "              self.P = np.random.rand(self.m, k)        # initialising the first factor embedding (of \"users\")\n",
    "              self.Q = np.random.rand(self.n, k)        # initialising the second factor embedding (of \"items\")\n",
    "              self.p_nnz_idx, self.q_nnz_idx = R.nonzero()        # row and col indices in R matrix respectively, of non-zero elements\n",
    "\n",
    "       def __predict_observed(self):\n",
    "              # print(np.shape(P[p_nnz_idx]), np.shape(Q[q_nnz_idx]))\n",
    "              R_predicted = np.sum( np.multiply(self.P[self.p_nnz_idx], self.Q[self.q_nnz_idx]), axis=1 )       #calculating the products only for the nonzero \"observed\" rating entries\n",
    "              R_predicted = sparse.csc_matrix( (R_predicted, (self.p_nnz_idx, self.q_nnz_idx)), shape=(self.m,self.n))\n",
    "\n",
    "              # print( np.shape(R_predicted))\n",
    "              # print(R_predicted)\n",
    "              \n",
    "              return R_predicted\n",
    "\n",
    "       # def __predict_observed(self):\n",
    "       #        R_predicted = self.P @ self.Q.T\n",
    "       #        R_predicted = sparse.csc_matrix(R_predicted)\n",
    "       #        return R_predicted\n",
    "\n",
    "       def gradients(self, R, _lambda):\n",
    "              \"\"\"\n",
    "              returns gradients w.r.t the elements of the embedding vectors\n",
    "              \"\"\"\n",
    "              # R_predicted = self.__predict_observed(self.R, self.P, self.Q)\n",
    "              R_predicted = self.__predict_observed()\n",
    "              error = R - R_predicted\n",
    "\n",
    "              # print(type(error), type(R), type(R_predicted))\n",
    "              # print( np.shape(error * self.Q), np.shape(_lambda*self.P) )\n",
    "              # print( type(error), type(self.Q), type(error * self.Q) )\n",
    "              # print(np.shape(error), type(error))\n",
    "              # print(error)\n",
    "              norm_factor = -2 / self.R.shape[0]\n",
    "              grad_P = norm_factor * (error*self.Q) + 2*(_lambda*self.P)\n",
    "              grad_Q = norm_factor * (error.T*self.P) + 2*(_lambda*self.Q)\n",
    "              return grad_P, grad_Q, error\n",
    "\n",
    "       def gradient_descent(self, iterations=2000, learning_rate = 0.1, _lambda=0):\n",
    "              grad_P, grad_Q, error = self.gradients(self.R, _lambda)\n",
    "              v_P = grad_P\n",
    "              v_Q = grad_Q\n",
    "              beta = 0.8    # momentum\n",
    "              print(\"train mse:\", error.power(2).sum()/self.R.shape[0] )\n",
    "              for i in range(iterations):\n",
    "                     grad_P, grad_Q, error = self.gradients(self.R, _lambda)\n",
    "                     v_P = beta*v_P + (1-beta)*grad_P\n",
    "                     v_Q = beta*v_Q + (1-beta)*grad_Q\n",
    "                     self.P = self.P - learning_rate*v_P\n",
    "                     self.Q = self.Q - learning_rate*v_Q\n",
    "                     # print(np.shape(error))\n",
    "                     # print(\"train mse:\", error.power(2).sum()/self.R.shape[0] )\n",
    "                     if(not (i+1)%50):\n",
    "                            print(\"\\niteration\", i+1, \":\")\n",
    "                            print(\"train mse:\", error.power(2).sum()/self.R.shape[0] )\n",
    "              return self.P, self.Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(611, 10) (9725, 10)\n"
     ]
    }
   ],
   "source": [
    "mf = MatrixFactorisation(train, 10)\n",
    "print( np.shape(mf.P), np.shape(mf.Q) )\n",
    "# print( mf.P )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse: 47.639789412277345\n",
      "\n",
      "iteration 50 :\n",
      "train mse: 46.69468618603528\n",
      "\n",
      "iteration 100 :\n",
      "train mse: 45.80448384130397\n",
      "\n",
      "iteration 150 :\n",
      "train mse: 44.98197347231309\n",
      "\n",
      "iteration 200 :\n",
      "train mse: 44.220294237190714\n",
      "\n",
      "iteration 250 :\n",
      "train mse: 43.51333647320343\n",
      "\n",
      "iteration 300 :\n",
      "train mse: 42.85568461577408\n",
      "\n",
      "iteration 350 :\n",
      "train mse: 42.24255160164141\n",
      "\n",
      "iteration 400 :\n",
      "train mse: 41.669710809924794\n",
      "\n",
      "iteration 450 :\n",
      "train mse: 41.13342965630901\n",
      "\n",
      "iteration 500 :\n",
      "train mse: 40.63040744681738\n",
      "\n",
      "iteration 550 :\n",
      "train mse: 40.15771896564603\n",
      "\n",
      "iteration 600 :\n",
      "train mse: 39.71276444337787\n",
      "\n",
      "iteration 650 :\n",
      "train mse: 39.29322596721012\n",
      "\n",
      "iteration 700 :\n",
      "train mse: 38.89703000636026\n",
      "\n",
      "iteration 750 :\n",
      "train mse: 38.522315493462486\n",
      "\n",
      "iteration 800 :\n",
      "train mse: 38.16740679016967\n",
      "\n",
      "iteration 850 :\n",
      "train mse: 37.83079083930364\n",
      "\n",
      "iteration 900 :\n",
      "train mse: 37.51109783791531\n",
      "\n",
      "iteration 950 :\n",
      "train mse: 37.20708483176317\n",
      "\n",
      "iteration 1000 :\n",
      "train mse: 36.91762171367141\n",
      "\n",
      "iteration 1050 :\n",
      "train mse: 36.64167919295731\n",
      "\n",
      "iteration 1100 :\n",
      "train mse: 36.37831838229957\n",
      "\n",
      "iteration 1150 :\n",
      "train mse: 36.12668171760504\n",
      "\n",
      "iteration 1200 :\n",
      "train mse: 35.88598498404577\n",
      "\n",
      "iteration 1250 :\n",
      "train mse: 35.65551026781949\n",
      "\n",
      "iteration 1300 :\n",
      "train mse: 35.4345996897256\n",
      "\n",
      "iteration 1350 :\n",
      "train mse: 35.22264980513841\n",
      "\n",
      "iteration 1400 :\n",
      "train mse: 35.01910657716404\n",
      "\n",
      "iteration 1450 :\n",
      "train mse: 34.823460847187995\n",
      "\n",
      "iteration 1500 :\n",
      "train mse: 34.63524424082099\n",
      "\n",
      "iteration 1550 :\n",
      "train mse: 34.4540254582744\n",
      "\n",
      "iteration 1600 :\n",
      "train mse: 34.27940690703718\n",
      "\n",
      "iteration 1650 :\n",
      "train mse: 34.111021641798374\n",
      "\n",
      "iteration 1700 :\n",
      "train mse: 33.948530582173476\n",
      "\n",
      "iteration 1750 :\n",
      "train mse: 33.791619983192874\n",
      "\n",
      "iteration 1800 :\n",
      "train mse: 33.639999136909815\n",
      "\n",
      "iteration 1850 :\n",
      "train mse: 33.49339828607512\n",
      "\n",
      "iteration 1900 :\n",
      "train mse: 33.351566732778\n",
      "\n",
      "iteration 1950 :\n",
      "train mse: 33.21427112642516\n",
      "\n",
      "iteration 2000 :\n",
      "train mse: 33.08129391655512\n",
      "(611, 10)\n"
     ]
    }
   ],
   "source": [
    "P, Q = mf.gradient_descent(iterations=2000, learning_rate=0.1, _lambda=0)\n",
    "print(np.shape(P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help = np.zeros((mf.P.shape[0], mf.Q.T.shape[1]))\n",
    "# print(np.shape(help))\n",
    "\n",
    "# for i in range(mf.P.shape[0]):\n",
    "#        for j in range(mf.Q.T.shape[1]):\n",
    "#               for k in range(mf.k):\n",
    "#                      help[i][j] += mf.P[i][k] * mf.Q.T[k][j]\n",
    "\n",
    "# print(help)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.41100543 0.75584689 0.08117057 ... 0.92413234 0.5204829  0.15446489]\n",
      " [1.00943587 0.16706719 1.47057236 ... 0.8999667  0.42411668 1.00865632]\n",
      " [0.96551131 0.09642666 0.50392217 ... 0.96584484 0.28503007 0.95188904]\n",
      " ...\n",
      " [1.36643691 0.21832797 1.15372701 ... 0.86486232 0.24416721 0.3644143 ]\n",
      " [0.8044081  0.01076732 0.37791874 ... 0.57012416 0.03161045 1.55030358]\n",
      " [0.56078029 1.27169228 0.98690866 ... 0.53588961 0.45196859 0.77140536]] \n",
      "\n",
      "\n",
      "\n",
      " [[0.16367328 0.70449521 0.41476788 ... 0.40783311 0.75031928 0.62704698]\n",
      " [1.11850844 0.72464111 0.33233906 ... 0.59692173 0.84342571 0.47134425]\n",
      " [0.8282649  0.89514434 0.47506307 ... 0.64428319 0.33005133 0.6373232 ]\n",
      " ...\n",
      " [0.17427384 0.59094777 0.96109792 ... 0.15780478 0.07836124 0.74024984]\n",
      " [0.27044104 0.72316968 0.60561996 ... 0.35376109 0.29613155 0.65295007]\n",
      " [0.16502885 0.04639174 0.87177167 ... 0.87485442 0.46799892 0.60803272]]\n"
     ]
    }
   ],
   "source": [
    "# help2 = mf.P @ mf.Q.T\n",
    "print(mf.P,\"\\n\\n\\n\\n\", mf.Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "        [4. , 4. , 4. , ..., 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "        ...,\n",
       "        [0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "        [3. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "        [5. , 0. , 5. , ..., 0. , 3.5, 0. ]])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> (array([  1,   1,   1, ..., 610, 610, 610]), array([   0,    1,    2, ..., 9720, 9721, 9723]))\n",
      "[[0.   0.   0.   ... 0.   0.   0.  ]\n",
      " [4.55 3.55 4.76 ... 0.   0.   0.  ]\n",
      " [0.   0.   0.   ... 0.   0.   0.  ]\n",
      " ...\n",
      " [0.   0.   0.   ... 0.   0.   0.  ]\n",
      " [3.48 0.   0.   ... 0.   0.   0.  ]\n",
      " [4.26 0.   4.41 ... 0.   3.52 0.  ]]\n"
     ]
    }
   ],
   "source": [
    "predictions = mf.P.dot(mf.Q.T)\n",
    "mask = np.zeros_like(train.toarray())\n",
    "print(type(predictions), type(train.toarray()), train.toarray().nonzero())\n",
    "mask[train.toarray().nonzero()] = 1\n",
    "\n",
    "# Mask out unknown ratings as 0 for ease of comparison.\n",
    "print(np.round(predictions * mask, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RecSys_Env",
   "language": "python",
   "name": "recsys_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
