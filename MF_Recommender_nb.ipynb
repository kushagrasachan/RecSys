{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System using Matrix Factorisation\n",
    "\n",
    "<!-- ### What this project does -->\n",
    "\n",
    "<!-- ### What this project doesn't do -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### For working on Google Colab #######\n",
    "# Uncomment the appropriate block below\n",
    "\n",
    "#### Download and unzip the 100k ratings Movielens dataset\n",
    "# !curl -O http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
    "# !unzip ml-latest-small.zip\n",
    "# !cd ml-latest-small/\n",
    "\n",
    "#### Download and unzip the 10 million ratings Movielens dataset\n",
    "# !curl -O https://files.grouplens.org/datasets/movielens/ml-10m.zip\n",
    "# !unzip ml-10m.zip\n",
    "# !cd ml-10M100K/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Until now, I've encountered two types of data objects in the Pandas library—DataFrames and Series, and here is a [Scaler Topics article on core components of Pandas](https://www.scaler.com/topics/pandas/core-components-of-pandas/), confirming that these two are the important ones (for single-dimensional, and two-dimensional data respectively), apart from a third object type, `Panel` (for three-dimensional data).\n",
    "\n",
    "Here's a micro-article attempting to list the organisation of files in Pandas' architecture: [Discover Pandas Library Architecture – File Hierarchy in Pandas](https://data-flair.training/blogs/pandas-library-architecture/) -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.read_csv(\"./ml-latest-small/ratings.csv\")\n",
    "# ratings_df = pd.read_csv(\"./ml-10M100K/ratings.dat\", delimiter='::', names=['userId', 'movieId', 'rating', 'timestamp'])\n",
    "# ratings_df = pd.read_csv(\"./anime-ratings-matrix-factorization-v-10/anime ratings dataset/rating.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100836 entries, 0 to 100835\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   userId     100836 non-null  int64  \n",
      " 1   movieId    100836 non-null  int64  \n",
      " 2   rating     100836 non-null  float64\n",
      " 3   timestamp  100836 non-null  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "ratings_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9724 movies and 610 users in the dataset\n"
     ]
    }
   ],
   "source": [
    "# num_movies = pd.DataFrame(ratings_df['movieId'].unique()).count().values[0]       #this is a tad more convoluted way\n",
    "# num_users = pd.DataFrame(ratings_df['userId'].unique()).count().values[0]\n",
    "num_movies = ratings_df['movieId'].unique().shape[0]                                #better way\n",
    "num_users = ratings_df['userId'].unique().shape[0]\n",
    "print(f\"There are {num_movies} movies and {num_users} users in the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 user IDs exceeding 610.\n",
      "There are 4334 movie IDs exceeding 9724.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {ratings_df.loc[ratings_df.userId > num_users].userId.unique().shape[0]} user IDs exceeding {num_users}.\")\n",
    "print(f\"There are {ratings_df.loc[ratings_df.movieId > num_movies].movieId.unique().shape[0]} movie IDs exceeding {num_movies}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 100k ratings dataset: it seems that the user IDs are contiguous, while the movie IDs are not.\n",
    "\n",
    "For the 10M ratings dataset: both the user IDs and movie IDs are not contiguous.\n",
    "\n",
    "We shall make the requisite IDs contiguous in following blocks after some more EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series.value_counts(ratings_df['rating']).to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(ratings_df['rating'], bins=[(i-1)/2 for i in range(0, 12)])\n",
    "# plt.hist(ratings_df['rating'], bins=[i-0.5 for i in range(-1,12)])  #for anime ratings dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId       0\n",
      "movieId      0\n",
      "rating       0\n",
      "timestamp    0\n",
      "dtype: int64 \n",
      "\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print( ratings_df.isna().sum() , \"\\n\")\n",
    "print( type(ratings_df.isna().sum()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100836"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( len(ratings_df.duplicated(subset=['userId', 'movieId'])) )\n",
    "len(np.where( ratings_df.duplicated(subset=['userId', 'movieId']) == False )[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There don't seem to be any duplicates *shruggie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy = np.zeros((3,4))\n",
    "# toy[0,1] = 1\n",
    "# toy[2,3] = 2\n",
    "# toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy_csc = sparse.csc_matrix(toy)\n",
    "# print( toy_csc.data )\n",
    "# print( toy_csc.nnz )  # nnz => no. of non-zero (entries)\n",
    "# print( toy_csc.nonzero() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy_csc.power(2).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "## This was an unsuccessful attempt to write a general function to make IDs contiguous ##\n",
    "############################################################################\n",
    "\n",
    "# def make_id_contiguous(df:pd.DataFrame, id:str):\n",
    "#        old_new_id = np.zeros(df[id].max()+1)\n",
    "#        for new_id, old_id in enumerate(df[id].unique()):\n",
    "#               old_new_id[old_id] = new_id\n",
    "              \n",
    "#        import re\n",
    "#        RE_WORDS = re.compile(r'''\n",
    "#                      # Find words in a string. Order matters!\n",
    "#                      [A-Z]+(?=[A-Z][a-z]) |  # All upper case before a capitalized word\n",
    "#                      [A-Z]?[a-z]+ |  # Capitalized words / all lower case\n",
    "#                      [A-Z]+ |  # All upper case\n",
    "#                      \\d+  # Numbers\n",
    "#                      ''', re.VERBOSE)\n",
    "#        id_split = RE_WORDS.findall(id)\n",
    "#        print(id_split)\n",
    "#        print(np.where(id_split == 'Id'))\n",
    "#        # id_split[np.where(id_split == 'Id')] = 'newId'\n",
    "#        new_id_name = \"\".join(i for i in id_split)\n",
    "\n",
    "#        df[new_id_name] = old_new_id[df[id]]\n",
    "#        df = df.astype({new_id_name: 'int64'})\n",
    "#        print( df.head(), \"\\n\" )\n",
    "#        return old_new_id\n",
    "\n",
    "# make_id_contiguous(ratings_df, 'movieId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the user and movie IDs contiguous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating  timestamp  userNewId\n",
      "0       1        1     4.0  964982703          0\n",
      "1       1        3     4.0  964981247          0\n",
      "2       1        6     4.0  964982224          0\n",
      "3       1       47     5.0  964983815          0\n",
      "4       1       50     5.0  964982931          0 \n",
      "\n",
      "       userId  userNewId\n",
      "22684     156        155\n",
      "22685     156        155\n",
      "22686     156        155\n",
      "22687     156        155\n",
      "22688     156        155\n",
      "...       ...        ...\n",
      "23077     156        155\n",
      "23078     156        155\n",
      "23079     156        155\n",
      "23080     156        155\n",
      "23081     156        155\n",
      "\n",
      "[398 rows x 2 columns] \n",
      "\n",
      "There are 610 users and correspondingly 610.0 contiguous user IDs now\n"
     ]
    }
   ],
   "source": [
    "user_old_new_id = np.zeros(ratings_df[\"userId\"].max()+1)\n",
    "for new_id, old_id in enumerate(ratings_df['userId'].unique()):\n",
    "       user_old_new_id[old_id] = new_id\n",
    "       \n",
    "ratings_df['userNewId'] = user_old_new_id[ratings_df['userId']]\n",
    "ratings_df = ratings_df.astype({'userNewId': 'int64'})\n",
    "\n",
    "print( ratings_df.head(), \"\\n\" )\n",
    "# now just to check that we did it correctly, a movieId should be mapped to the same movieNewId\n",
    "print( ratings_df.loc[ratings_df.userId == 156][['userId', 'userNewId']], \"\\n\" ) \n",
    "print(f\"There are {num_users} users and correspondingly {max(user_old_new_id)+1} contiguous user IDs now\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating  timestamp  userNewId  movieNewId\n",
      "0       1        1     4.0  964982703          0           0\n",
      "1       1        3     4.0  964981247          0           1\n",
      "2       1        6     4.0  964982224          0           2\n",
      "3       1       47     5.0  964983815          0           3\n",
      "4       1       50     5.0  964982931          0           4 \n",
      "\n",
      "       movieId  movieNewId\n",
      "17007      156        4463\n",
      "96137      156        4463\n",
      "97391      156        4463 \n",
      "\n",
      "There are 9724 movies and correspondingly 9724.0 contiguous movie IDs now\n"
     ]
    }
   ],
   "source": [
    "movie_old_new_id = np.zeros(ratings_df[\"movieId\"].max()+1)\n",
    "for new_id, old_id in enumerate(ratings_df['movieId'].unique()):\n",
    "       movie_old_new_id[old_id] = new_id\n",
    "       \n",
    "ratings_df['movieNewId'] = movie_old_new_id[ratings_df['movieId']]\n",
    "ratings_df = ratings_df.astype({'movieNewId': 'int64'})\n",
    "\n",
    "print( ratings_df.head(), \"\\n\" )\n",
    "# now just to check that we did it correctly, a movieId should be mapped to the same movieNewId\n",
    "print( ratings_df.loc[ratings_df.movieId == 156][['movieId', 'movieNewId']], \"\\n\" ) \n",
    "print(f\"There are {num_movies} movies and correspondingly {max(movie_old_new_id)+1} contiguous movie IDs now\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       userId  movieId  rating   timestamp  userNewId  movieNewId\n",
      "0         509     7347     3.0  1435994597        508        4285\n",
      "1         326    71462     4.0  1322252335        325        5629\n",
      "2          57     2115     3.0   965798155         56         134\n",
      "3         610     1127     4.0  1479544102        609          66\n",
      "4         462     2409     2.0  1174438249        461        1172\n",
      "...       ...      ...     ...         ...        ...         ...\n",
      "80663      42     4005     4.0   996259059         41        1873\n",
      "80664     364      141     4.0   869443367        363         524\n",
      "80665     480     6867     4.0  1179163171        479        2240\n",
      "80666       6      981     3.0   845556567          5         712\n",
      "80667     103     6711     5.0  1431957425        102        2046\n",
      "\n",
      "[80668 rows x 6 columns]\n",
      "       userId  movieId  rating   timestamp  userNewId  movieNewId\n",
      "0         432    77866     4.5  1335139641        431        4730\n",
      "1         288      474     3.0   978465565        287         474\n",
      "2         599     4351     3.0  1498524542        598        2631\n",
      "3          42     2987     4.0   996262677         41         194\n",
      "4          75     1610     4.0  1158989841         74         727\n",
      "...       ...      ...     ...         ...        ...         ...\n",
      "20163     380     5048     2.0  1494268065        379         279\n",
      "20164     434    54272     3.5  1270606860        433        1269\n",
      "20165     226     5989     4.5  1162428551        225         765\n",
      "20166     607     1320     3.0   963080497        606        2750\n",
      "20167     567      750     3.0  1525287719        566         722\n",
      "\n",
      "[20168 rows x 6 columns]\n",
      "(80668, 6) (20168, 6)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(ratings_df, test_size=0.2, random_state=42)  #setting random_state ensures consistent splitting every time\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "print(train_df)\n",
    "print(test_df)\n",
    "print( np.shape(train_df), np.shape(test_df) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we've chosen to make the movie IDs contiguous by mapping them to new ones, splitting the DataFrame makes creating smaller-dimensional matrix representations of the training or test sets difficult, because, say, the indices chosen in the training set can still lie out of bounds of its smaller matrix's size (similar logic holds for the test set).\n",
    "\n",
    "Instead, let's just work with the full ratings matrix, with the test entries zeroed out in the training matrix (and vice versa), which wouldn't be a bother to the memory anyway because we're using a sparse representation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 80668 & 20168 non-zero elements in the train and test sparse matrices respectively.\n",
      " 611 9725\n"
     ]
    }
   ],
   "source": [
    "train = sparse.csc_matrix( (train_df['rating'].values, (train_df['userNewId'].values, train_df['movieNewId'].values)),\\\n",
    "                                 shape=(num_users+1, num_movies+1) )\n",
    "test = sparse.csc_matrix(  (test_df['rating'].values, (test_df['userNewId'].values, test_df['movieNewId'].values)),\\\n",
    "                                 shape=(num_users+1, num_movies+1))\n",
    "\n",
    "print(f\"There are {train.nnz} & {test.nnz} non-zero elements in the train and test sparse matrices respectively.\\n\", test.shape[0],train.shape[1] )\n",
    "# train.to_dense()\n",
    "# print( train )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemme check once that the test and train matrix elements are indeed mutually exclusive (zero, non-zero in their matrices respectively).\n",
    "\n",
    "The cell below seems to show all's good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in zip(test.nonzero()[0], test.nonzero()[1]):\n",
    "#        if( train[i[0],i[1]] != 0 ):\n",
    "#               print(\"Hah!\")\n",
    "# for i in zip(train.nonzero()[0], train.nonzero()[1]):\n",
    "#        if( test[i[0],i[1]] != 0 ):\n",
    "#               print(\"Hah!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print( np.sort(train_df['userId'].values) )\n",
    "# print( mf.p_nnz_idx, \"\\n\" )\n",
    "\n",
    "# print( np.sort(train_df['movieNewId'].values) )\n",
    "# print( np.sort(mf.q_nnz_idx ) )\n",
    "# print( np.sort(train_df['userId'].values) == mf.p_nnz_idx )\n",
    "# print( np.sort(train_df['movieNewId'].values) == np.sort(mf.q_nnz_idx), \"\\n\" )\n",
    "\n",
    "# print( np.where( np.sort(train_df['userId'].values) != train.nonzero()[0]) )\n",
    "# print( np.where( np.sort(train_df['movieNewId'].values) != np.sort( train.nonzero()[1]) ) )\n",
    "# print( np.where( np.sort(train_df['movieNewId'].values) != np.sort(mf.q_nnz_idx)) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm, so the row indices seem to be all good, ~~but the column indices are playing foul.~~ as do the column indices.\n",
    "\n",
    "Wasted quite the time pursuing this!\n",
    "\n",
    "We have used the list `train_df['movieNewId'].values` as the column indices needed to generate R, but upon querying back these column indices, ~~they're coming out wrong!~~\n",
    "Previously, I wasn ony sorting the `train_df['movieNewId'].values` list, and not the list `mf.q_nnz_idx` for comparison. Upon sorting both, they indeed come out to be the same.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorisation Class\n",
    "Below, I furnish a Matrix Factorisation Python class that implements:\n",
    "- gradient descent\n",
    "- (pending) gradient descent with user and item biases\n",
    "- sgd\n",
    "- ALS\n",
    "to learn the embeddings.\n",
    "\n",
    "The implementation of gradient descent and sgd considers the loss function for explicit ratings, i.e. solely over observed values.\n",
    "The ALS implementation uses the Koren et al. approach treating the entire ratings matrix as dense implicit data.\n",
    "\n",
    "The regularised loss I've used for explicit ratings: $$L(R, P, Q) = \\frac{1}{N}\\underset{(i,j):r_{ui}≠Nan}{\\sum} (r_{ui} - p_u^T\\cdot q_i)^2 + \\lambda(\\sum_u{||p_u||^2} + \\sum_i{||q_i||^2})$$\n",
    "It's a squared error (SE) loss function with regularisation terms. I wonder how using the Mean SE or RMSE would change the behaviour. ~~Conceptually, it shouldn't..~~ Oh how pathetically wrong I was! Not providing the required normalisation on the gradient terms just blew the cost up! I wonder why not providing the normalisation to the gradient calculation blows up the cost. The two seem unrelated, except, not!\n",
    "\n",
    "Still need to add the user and item bias terms to SGD and GD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorisation():\n",
    "       def __init__(self, R:sparse.csc_matrix, k:int, verbose:bool=False ):\n",
    "              self.R = R           # R is the \"ratings\" matrix to be factorised\n",
    "              self.k = k           # hyperparameter k is the number of latent factors desired in the factorised embeddings\n",
    "              self.m, self.n = R.shape\n",
    "              self.P = np.random.rand(self.m, k)        # initialising the first factor embedding (of \"users\")\n",
    "              self.Q = np.random.rand(self.n, k)        # initialising the second factor embedding (of \"items\")\n",
    "              self.p_nnz_idx, self.q_nnz_idx = R.nonzero()        # row and col indices in R matrix respectively, of non-zero elements\n",
    "              self.train_mse_at_epochs = []\n",
    "              self.test_mse_at_epochs = []\n",
    "              self.verbose = verbose\n",
    "              self.verbose_epoch_intvl = 50\n",
    "\n",
    "       def __predict_observed(self):\n",
    "              \"\"\"\n",
    "              Returns predicted values as a sparse matrix, corresponding to indices of non-zero elements in matrix R to be factorised\n",
    "\n",
    "              Avoids constructing a dense prediction matrix produced via naïve dense matrix multiplication of factors.\n",
    "              Instead, produces predicted values by multiplying only the requisite factor vectors corresponding to non-zero entries in R.\n",
    "              \"\"\"\n",
    "              R_predicted = np.sum( np.multiply(self.P[self.p_nnz_idx], self.Q[self.q_nnz_idx]), axis=1 )       #calculating the products only for the nonzero \"observed\" rating entries: explicit MF\n",
    "              R_predicted = sparse.csc_matrix( (R_predicted, (self.p_nnz_idx, self.q_nnz_idx)), shape=(self.m,self.n))              \n",
    "              # R_predicted = self.P @ self.Q.T\n",
    "              # R_predicted = sparse.csc_matrix(R_predicted)\n",
    "              return R_predicted\n",
    "\n",
    "       def gradients(self, _lambda):\n",
    "              \"\"\"\n",
    "              Returns l2 gradients w.r.t the elements of the embedding vectors, along with the prediction errors\n",
    "              \"\"\"\n",
    "              R_predicted = self.__predict_observed()\n",
    "              error = self.R - R_predicted\n",
    "              norm_factor = -2 / self.R.nnz  #this factor is crucial! Can't be 1 (i.e. we can't leave the gradients unnormalised, else cost diverges!)\n",
    "              grad_P = norm_factor * (error*self.Q) + 2*(_lambda*self.P)\n",
    "              grad_Q = norm_factor * (error.T*self.P) + 2*(_lambda*self.Q)\n",
    "              return grad_P, grad_Q, error\n",
    "\n",
    "       def gradient_descent(self, iterations=2000, learning_rate = 0.3, _lambda=0.0002, beta=0.8, validation:sparse.csc_matrix=None, verbose=False):\n",
    "              \"\"\"\n",
    "              Returns factor matrices for explicit data matrix by learning their entries via full-batch gradient descent.\n",
    "\n",
    "              Returned factor matrices P,Q represent user and item embeddings, for explicit ratings data R.\n",
    "                     R = P.Q^T\n",
    "\n",
    "              Optionally provide a sparse matrix with validation data, to compute the validation performance (measured by mse) over time\n",
    "              \"\"\"\n",
    "              self.verbose = verbose\n",
    "\n",
    "              grad_P, grad_Q, error = self.gradients(_lambda)\n",
    "              v_P = grad_P\n",
    "              v_Q = grad_Q\n",
    "              beta = beta    # momentum constant\n",
    "              train_mse = error.power(2).sum()/self.R.nnz #self.R.shape[0]\n",
    "              # print(\"train mse:\", train_mse)\n",
    "              self.train_mse_at_epochs.append( [1, train_mse] )\n",
    "              self.save_test_mse(0, validation=validation)\n",
    "              for i in tqdm(range(iterations), desc=\"Gradient Descent progress:\", leave=verbose):\n",
    "                     grad_P, grad_Q, error = self.gradients(_lambda)\n",
    "                     v_P = beta*v_P + (1-beta)*grad_P   \n",
    "                     v_Q = beta*v_Q + (1-beta)*grad_Q\n",
    "                     self.P = self.P - learning_rate*v_P       # Grad Desc update rule\n",
    "                     self.Q = self.Q - learning_rate*v_Q       # Grad Desc update rule\n",
    "                     # print(\"train mse:\", error.power(2).sum()/self.R.shape[0] )  #print mse at each iteration\n",
    "                     if(not (i+1)%self.verbose_epoch_intvl):\n",
    "                            self.save_train_mse(i, error)\n",
    "                            self.save_test_mse(i, validation=validation)\n",
    "              return self.P, self.Q\n",
    "\n",
    "       def save_train_mse(self, i, error):\n",
    "              train_mse = error.power(2).sum()/self.R.nnz #self.R.shape[0]\n",
    "              self.train_mse_at_epochs.append( [i+1, train_mse])\n",
    "              if(self.verbose):\n",
    "                     print(\"\\niteration/epoch\", i+1, \":\")\n",
    "                     print(\"train mse:\", train_mse)\n",
    "\n",
    "       def save_test_mse(self, i, validation:sparse.csc_matrix=None, solver='gd'):\n",
    "              if(validation != None):\n",
    "                     valdn_p_nnz_idx, valdn_q_nnz_idx = validation.nonzero()\n",
    "                     valdn_predicted = np.sum( np.multiply(self.P[valdn_p_nnz_idx], self.Q[valdn_q_nnz_idx]), axis=1 )       #calculating the products only for the nonzero \"observed\" rating entries\n",
    "                     valdn_predicted = sparse.csc_matrix( (valdn_predicted, (valdn_p_nnz_idx, valdn_q_nnz_idx)), shape=(self.m,self.n))\n",
    "                     # if(solver == 'als'):\n",
    "                     #        valdn_Phi = validation\n",
    "                     #        valdn_Phi[valdn_Phi.nonzero()] = 1.0\n",
    "                     #        valdn_error = valdn_Phi- valdn_predicted\n",
    "                     #        # test_mse = valdn_error.power(2).sum()/self.R.nnz   #self.R.shape[0]\n",
    "                     # else:\n",
    "                     #        # valdn_p_nnz_idx, valdn_q_nnz_idx = validation.nonzero()\n",
    "                     #        # valdn_predicted = np.sum( np.multiply(self.P[valdn_p_nnz_idx], self.Q[valdn_q_nnz_idx]), axis=1 )       #calculating the products only for the nonzero \"observed\" rating entries\n",
    "                     #        # valdn_predicted = sparse.csc_matrix( (valdn_predicted, (valdn_p_nnz_idx, valdn_q_nnz_idx)), shape=(self.m,self.n))\n",
    "                     valdn_error = validation - valdn_predicted\n",
    "                     test_mse = valdn_error.power(2).sum()/self.R.nnz   #self.R.shape[0]\n",
    "                     self.test_mse_at_epochs.append([i+1, test_mse])\n",
    "                     if(self.verbose):\n",
    "                            print(\"iteration\", i+1, \":\")\n",
    "                            print(\"test mse:\", test_mse)\n",
    "\n",
    "       def sgd(self, epochs=30, learning_rate=0.003, _lambda=0.0002, beta=0.8, verbose=False, validation:sparse.csc_matrix=None):\n",
    "              \"\"\"\n",
    "              Returns factor matrices for explicit data matrix by learning their entries via stochastic gradient descent.\n",
    "\n",
    "              Returned factor matrices P,Q represent user and item embeddings, for explicit ratings data R.\n",
    "                     R = P.Q^T\n",
    "              \"\"\"\n",
    "              self.verbose = verbose\n",
    "              beta = beta\n",
    "\n",
    "              num_samples = len(self.p_nnz_idx)\n",
    "              training_indices = np.arange(num_samples)\n",
    "              # I couldn't have shuffled the array p_nnz_idx itself, cuz that would require shuffling q_nnx_idx in a corresponding manner\n",
    "\n",
    "              # with tqdm(total=100) as prog_bar:\n",
    "              for epoch in tqdm(range(epochs), desc=\"Total SGD epochs completion: \"):\n",
    "                     np.random.shuffle(training_indices)       #stochasticity must be ensured properly!\n",
    "                     count = 0\n",
    "                     for i in tqdm(training_indices, desc=f\"Epoch #{epoch} completion: \"):         #We need to update all users and items at least once in each iteration\n",
    "                            p_idx = self.p_nnz_idx[i]\n",
    "                            q_idx = self.q_nnz_idx[i]\n",
    "\n",
    "                            R_ij = self.R[p_idx, q_idx]\n",
    "                            P_i = self.P[p_idx]\n",
    "                            Q_j = self.Q[q_idx]\n",
    "\n",
    "                            R_predicted_ij = P_i.dot(Q_j.T)\n",
    "                            error_ij = R_ij - R_predicted_ij\n",
    "                            grad_P_i = -2*(error_ij * Q_j) + 2*(_lambda * self.P[p_idx])\n",
    "                            grad_Q_j = -2*(error_ij * P_i) + 2*(_lambda * self.Q[q_idx])\n",
    "\n",
    "                            v_P_i = beta*v_P_i + (1-beta)*grad_P_i if epoch!=0 else grad_P_i\n",
    "                            v_Q_j = beta*v_Q_j + (1-beta)*grad_Q_j if epoch!=0 else grad_Q_j\n",
    "       \n",
    "                            self.P[p_idx] -= learning_rate * v_P_i\n",
    "                            self.Q[q_idx] -= learning_rate * v_Q_j\n",
    "                            # self.P[p_idx] -= learning_rate* grad_P_i\n",
    "                            # self.Q[q_idx] -= learning_rate* grad_Q_j\n",
    "\n",
    "                            if(not ((epoch+1)*(count+1)+1)%(1000)):\n",
    "                                   R_predicted = np.sum( np.multiply(self.P[self.p_nnz_idx], self.Q[self.q_nnz_idx]), axis=1 )       #calculating the products only for the nonzero \"observed\" rating entries\n",
    "                                   R_predicted = sparse.csc_matrix( (R_predicted, (self.p_nnz_idx, self.q_nnz_idx)), shape=(self.m,self.n))\n",
    "                                   error = self.R - R_predicted\n",
    "                                   self.save_train_mse((epoch+1)*(count+1), error)\n",
    "                                   self.save_test_mse((epoch+1)*(count+1), validation=validation)\n",
    "                            count += 1\n",
    "\n",
    "                     # if(not (epoch+1)%(self.verbose_epoch_intvl/10)):\n",
    "                     #        R_predicted = np.sum( np.multiply(self.P[self.p_nnz_idx], self.Q[self.q_nnz_idx]), axis=1 )       #calculating the products only for the nonzero \"observed\" rating entries\n",
    "                     #        R_predicted = sparse.csc_matrix( (R_predicted, (self.p_nnz_idx, self.q_nnz_idx)), shape=(self.m,self.n))\n",
    "                     #        error = self.R - R_predicted\n",
    "                     #        self.save_train_mse(count, error)\n",
    "                     #        # self.save_test_mse(i, validation=validation)\n",
    "              return self.P, self.Q\n",
    "\n",
    "       def als(self, epochs=10, alpha=40, _lambda=10, solver=\"cg\", validation:sparse.csc_matrix=None, verbose=False):\n",
    "              \"\"\"\n",
    "              Returns factor matrices for implicit data matrix by learning their entries via Alternating Least Squares method.\n",
    "\n",
    "              Returned factor matrices P,Q represent user and item embeddings, for binarised ratings data Phi derived from R.\n",
    "                     Phi[p,q] =    { 0    for R[p,q]=0\n",
    "                                   { 1    for R[p,q]>0\n",
    "              &      Phi = P.Q^T\n",
    "\n",
    "              Uses scipy.sparse.linalg's spsolve as its solver\n",
    "              \"\"\"\n",
    "              ## should I be making the following tradeoff for precomputed memory, to speed up implementation?\n",
    "              # Cp_array = []\n",
    "              # Cq_array = []\n",
    "              # for p in range(self.m):\n",
    "              #        C_p = sparse.diags(self.R[p].toarray(), [0])\n",
    "              #        Cp_array.append(C_p)\n",
    "              # for q in range(self.n):\n",
    "              #        C_q = sparse.diags(self.R[q].toarray(), [0])\n",
    "              #        Cq_array.append(C_q)\n",
    "              self.verbose = verbose\n",
    "              lambda_eye = _lambda * sparse.eye(self.k)\n",
    "\n",
    "              P = sparse.csc_matrix(self.P)\n",
    "              Q = sparse.csc_matrix(self.Q)\n",
    "\n",
    "              # the memory for this loop can further be optimised by eliminating the two similar loops with appropriate conditioning\n",
    "              for i in tqdm(range(epochs), desc=\"ALS iterations completion: \"):\n",
    "                     # Q = sparse.csc_matrix(self.Q)\n",
    "                     QTQ = Q.T.dot(Q)         #precomputation of Q.T.dot(Q) for all elements of P\n",
    "                     for p in tqdm(range(self.m), desc=\"Solving for P: \", leave=True):\n",
    "                            R_p = self.R[p].toarray()\n",
    "                            CpI = sparse.diags(alpha * R_p, [0])      #This acts as the (C^u - I) matrix in literature\n",
    "                            QTCpIQ = Q.T.dot(CpI).dot(Q)\n",
    "                            A = (QTQ + QTCpIQ) + lambda_eye\n",
    "\n",
    "                            phi = R_p.copy()\n",
    "                            phi[np.where(phi != 0)] = 1.0\n",
    "                            b = Q.T.dot(CpI + sparse.eye(self.n)).dot(sparse.csc_matrix(phi).T)       # why the last transpose on phi though?\n",
    "\n",
    "                            if(solver == \"lu\"):\n",
    "                                   P[p] = sparse.linalg.spsolve(A, b)\n",
    "                                   # self.P[p] = sparse.linalg.spsolve(A, b)\n",
    "                            if(solver == \"cg\"):\n",
    "                                   P[p], exitcode = sparse.linalg.cg(A, b.toarray())\n",
    "                                   if(exitcode):\n",
    "                                          print(f\"Conjugate Gradient Method couldn't converge properly, exited with convergence exitcode {exitcode}\")\n",
    "                     \n",
    "                     # P = sparse.csc_matrix(self.P)\n",
    "                     PTP = P.T.dot(P)         #precomputation of P.T.dot(P) for all elements of Q\n",
    "                     for q in tqdm(range(self.n), desc=\"Solving for Q: \"):\n",
    "                            R_q = self.R[:,q].T.toarray()\n",
    "                            CqI = sparse.diags(alpha * R_q, [0])      #This acts as the (C^u - I) matrix in literature\n",
    "                            PTCqIP = P.T.dot(CqI).dot(P)\n",
    "                            A = (PTP + PTCqIP) + lambda_eye\n",
    "\n",
    "                            phi = R_q.copy()\n",
    "                            phi[np.where(phi != 0)] = 1.0\n",
    "                            b = P.T.dot(CqI + sparse.eye(self.m)).dot(sparse.csc_matrix(phi).T)       # why the last transpose on phi though?\n",
    "\n",
    "                            if(solver == \"lu\"):\n",
    "                                   Q[q] = sparse.linalg.spsolve(A, b)\n",
    "                                   # self.Q[q] = sparse.linalg.spsolve(A, b)\n",
    "                            if(solver == \"cg\"):\n",
    "                                   Q[q], exitcode = sparse.linalg.cg(A, b.toarray())\n",
    "                                   if(exitcode):\n",
    "                                          print(f\"Conjugate Gradient Method couldn't converge properly, exited with convergence exitcode {exitcode}\")\n",
    "\n",
    "                     # Phi_predicted = np.sum( np.multiply(self.P[self.p_nnz_idx], self.Q[self.q_nnz_idx]), axis=1 )       #calculating the products only for the nonzero \"observed\" rating entries\n",
    "                     # Phi_predicted = sparse.csc_matrix( (Phi_predicted, (self.p_nnz_idx, self.q_nnz_idx)), shape=(self.m,self.n))\n",
    "                     Phi_predicted = np.sum( np.multiply(P.toarray()[self.p_nnz_idx], Q.toarray()[self.q_nnz_idx]), axis=1 )       #calculating the products only for the nonzero \"observed\" rating entries\n",
    "                     Phi_predicted = sparse.csc_matrix( (Phi_predicted, (self.p_nnz_idx, self.q_nnz_idx)), shape=(self.m,self.n))\n",
    "                     Phi = self.R\n",
    "                     Phi[Phi.nonzero()] = 1.0\n",
    "                     error = Phi - Phi_predicted\n",
    "                     self.save_train_mse(i, error)\n",
    "\n",
    "                     valdn_p_nnz_idx, valdn_q_nnz_idx = validation.nonzero()\n",
    "                     valdn_predicted = np.sum( np.multiply(P.toarray()[valdn_p_nnz_idx], Q.toarray()[valdn_q_nnz_idx]), axis=1 )       #calculating the products only for the nonzero \"observed\" rating entries\n",
    "                     valdn_predicted = sparse.csc_matrix( (valdn_predicted, (valdn_p_nnz_idx, valdn_q_nnz_idx)), shape=(self.m,self.n))\n",
    "                     valdn_Phi = validation\n",
    "                     valdn_Phi[valdn_Phi.nonzero()] = 1.0\n",
    "                     valdn_error = valdn_Phi- valdn_predicted\n",
    "                     test_mse = valdn_error.power(2).sum()/self.R.nnz   #self.R.shape[0]\n",
    "                     self.test_mse_at_epochs.append([i+1, test_mse])\n",
    "                     if(self.verbose):\n",
    "                            print(\"iteration\", i+1, \":\")\n",
    "                            print(\"test mse:\", test_mse)\n",
    "              self.P = P\n",
    "              self.Q = Q\n",
    "              return self.P, self.Q\n",
    "\n",
    "       def plot_learning_curve(self, validation=None):\n",
    "              if(validation != None):\n",
    "                     test_mse_arr = np.array(self.test_mse_at_epochs)\n",
    "                     plt.plot(test_mse_arr[:,0], test_mse_arr[:,1], label='Test')\n",
    "              train_mse_arr = np.array(self.train_mse_at_epochs)\n",
    "              plt.plot(train_mse_arr[:,0], train_mse_arr[:,1], label='Train')\n",
    "              plt.xticks(fontsize=16)\n",
    "              plt.yticks(fontsize=16)\n",
    "              plt.xlabel('iterations', fontsize=12)\n",
    "              plt.ylabel('MSE', fontsize=12)\n",
    "              plt.legend(loc='best', fontsize=9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54d622216744f0c8f14d1752830d47a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Grid Search Progress: : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c675aa1e33742ba895c74a60e67e24e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Gradient Descent progress::   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations: 1000 | learning_rate: 0.3 | _lambda: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f617b8ea6c44abeb7bbfb790d82b366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Gradient Descent progress::   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations: 1000 | learning_rate: 0.3 | _lambda: 0.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7078933528c4670b9cb448c5931856e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Gradient Descent progress::   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations: 1000 | learning_rate: 0.3 | _lambda: 0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a95e03802e403ea158f5c24f2a2a6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Gradient Descent progress::   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations: 1000 | learning_rate: 0.3 | _lambda: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86864ac182d74775b6f87c4bfe549344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Gradient Descent progress::   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations: 1000 | learning_rate: 0.5 | _lambda: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0ecedd672a447baccd37aa42efb35d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Gradient Descent progress::   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations: 1000 | learning_rate: 0.5 | _lambda: 0.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d1b6d4eb2e46c48a73c8dd2eed75dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Gradient Descent progress::   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations: 1000 | learning_rate: 0.5 | _lambda: 0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5312f688c0b543718284ec0af574b5d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Gradient Descent progress::   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations: 1000 | learning_rate: 0.5 | _lambda: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e508529afd4bdeb49ddb8239d96cbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Gradient Descent progress::   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations: 3000 | learning_rate: 0.3 | _lambda: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7946f6d1d2440c4940a9da03e473186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Gradient Descent progress::   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations: 3000 | learning_rate: 0.3 | _lambda: 0.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25959606f5d84f70a68361c0bf1e6110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Gradient Descent progress::   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations: 3000 | learning_rate: 0.3 | _lambda: 0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e960e9c5ee284eb583bae1cb457c9335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Gradient Descent progress::   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations: 3000 | learning_rate: 0.3 | _lambda: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f5c0cebf98e4a16bf472c864e8dd4a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Gradient Descent progress::   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations: 3000 | learning_rate: 0.5 | _lambda: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c173ebeffb74635beb4e74d9954b933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Gradient Descent progress::   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 53\u001b[0m\n\u001b[1;32m     41\u001b[0m param_grid_gd \u001b[38;5;241m=\u001b[39m {   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m80\u001b[39m],\n\u001b[1;32m     42\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miterations\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m3000\u001b[39m, \u001b[38;5;241m10000\u001b[39m],\n\u001b[1;32m     43\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.5\u001b[39m],\n\u001b[1;32m     44\u001b[0m                     \u001b[38;5;66;03m# \"beta\": [0.5, 0.9],\u001b[39;00m\n\u001b[1;32m     45\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_lambda\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1e-1\u001b[39m, \u001b[38;5;241m1e-2\u001b[39m, \u001b[38;5;241m10\u001b[39m]}\n\u001b[1;32m     47\u001b[0m param_grid_sgd \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m80\u001b[39m],\n\u001b[1;32m     48\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[1;32m     49\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m0.003\u001b[39m, \u001b[38;5;241m0.03\u001b[39m, \u001b[38;5;241m0.3\u001b[39m],\n\u001b[1;32m     50\u001b[0m                     \u001b[38;5;66;03m# \"beta\": [0.5, 0.9],\u001b[39;00m\n\u001b[1;32m     51\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_lambda\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1e-1\u001b[39m, \u001b[38;5;241m1e-2\u001b[39m, \u001b[38;5;241m10\u001b[39m]}\n\u001b[0;32m---> 53\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid_gd\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[50], line 15\u001b[0m, in \u001b[0;36mgrid_search\u001b[0;34m(model, train, test, param_grid, user_index)\u001b[0m\n\u001b[1;32m     13\u001b[0m     mf\u001b[38;5;241m.\u001b[39mals(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, validation\u001b[38;5;241m=\u001b[39mtest)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m(model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgd\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 15\u001b[0m     \u001b[43mmf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m(model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msgd\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     17\u001b[0m     mf\u001b[38;5;241m.\u001b[39msgd(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, validation\u001b[38;5;241m=\u001b[39mtest)\n",
      "Cell \u001b[0;32mIn[49], line 58\u001b[0m, in \u001b[0;36mMatrixFactorisation.gradient_descent\u001b[0;34m(self, iterations, learning_rate, _lambda, beta, validation, verbose)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_test_mse(\u001b[38;5;241m0\u001b[39m, validation\u001b[38;5;241m=\u001b[39mvalidation)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(iterations), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradient Descent progress:\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39mverbose):\n\u001b[0;32m---> 58\u001b[0m        grad_P, grad_Q, error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_lambda\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m        v_P \u001b[38;5;241m=\u001b[39m beta\u001b[38;5;241m*\u001b[39mv_P \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mbeta)\u001b[38;5;241m*\u001b[39mgrad_P   \n\u001b[1;32m     60\u001b[0m        v_Q \u001b[38;5;241m=\u001b[39m beta\u001b[38;5;241m*\u001b[39mv_Q \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mbeta)\u001b[38;5;241m*\u001b[39mgrad_Q\n",
      "Cell \u001b[0;32mIn[49], line 31\u001b[0m, in \u001b[0;36mMatrixFactorisation.gradients\u001b[0;34m(self, _lambda)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, _lambda):\n\u001b[1;32m     28\u001b[0m \u001b[38;5;250m       \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m       Returns l2 gradients w.r.t the elements of the embedding vectors, along with the prediction errors\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m       \"\"\"\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m        R_predicted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__predict_observed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m        error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mR \u001b[38;5;241m-\u001b[39m R_predicted\n\u001b[1;32m     33\u001b[0m        norm_factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mR\u001b[38;5;241m.\u001b[39mnnz  \u001b[38;5;66;03m#this factor is crucial! Can't be 1 (i.e. we can't leave the gradients unnormalised, else cost diverges!)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[49], line 21\u001b[0m, in \u001b[0;36mMatrixFactorisation.__predict_observed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__predict_observed\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     15\u001b[0m \u001b[38;5;250m       \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m       Returns predicted values as a sparse matrix, corresponding to indices of non-zero elements in matrix R to be factorised\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m       Avoids constructing a dense prediction matrix produced via naïve dense matrix multiplication of factors.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m       Instead, produces predicted values by multiplying only the requisite factor vectors corresponding to non-zero entries in R.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m       \"\"\"\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m        R_predicted \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mP\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_nnz_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mQ\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_nnz_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m       \u001b[38;5;66;03m#calculating the products only for the nonzero \"observed\" rating entries: explicit MF\u001b[39;00m\n\u001b[1;32m     22\u001b[0m        R_predicted \u001b[38;5;241m=\u001b[39m sparse\u001b[38;5;241m.\u001b[39mcsc_matrix( (R_predicted, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp_nnz_idx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_nnz_idx)), shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn))              \n\u001b[1;32m     23\u001b[0m        \u001b[38;5;66;03m# R_predicted = self.P @ self.Q.T\u001b[39;00m\n\u001b[1;32m     24\u001b[0m        \u001b[38;5;66;03m# R_predicted = sparse.csc_matrix(R_predicted)\u001b[39;00m\n",
      "File \u001b[0;32m~/Py_VirtualEnvs/RecSys_Env/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2313\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2310\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   2311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m-> 2313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2314\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Py_VirtualEnvs/RecSys_Env/lib/python3.10/site-packages/numpy/core/fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "def grid_search(model, train, test, param_grid, user_index=None):\n",
    "    curves = []\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    for v in tqdm(itertools.product(*values), desc=\"Grid Search Progress: \"):\n",
    "        # print(v)\n",
    "        params = dict(zip(keys, v))\n",
    "        mf = MatrixFactorisation(train, params[\"k\"])\n",
    "        params = dict(list(params.items())[1:])\n",
    "        if(model == \"als\"):\n",
    "            mf.als(**params, validation=test)\n",
    "        elif(model == \"gd\"):\n",
    "            mf.gradient_descent(**params, validation=test)\n",
    "        elif(model == \"sgd\"):\n",
    "            mf.sgd(**params, validation=test)\n",
    "\n",
    "        train_mse = mf.train_mse_at_epochs\n",
    "        test_mse = mf.test_mse_at_epochs\n",
    "\n",
    "        curves.append({'params': params, 'mse': {'train': train_mse, 'test': test_mse}})\n",
    "\n",
    "        print_line = []\n",
    "        for k, v in params.items():\n",
    "            print_line.append((k, v))\n",
    "\n",
    "        print(' | '.join('{}: {}'.format(k, v) for (k, v) in print_line))\n",
    "        # _, train_patk, train_mse, test_patk, test_mse = learning_curve(this_model, train, test, epochs, k=patk, user_index=user_index)\n",
    "        # curves.append({'params': params,\n",
    "        #                'patk': {'train': train_patk, 'test': test_patk},\n",
    "        #                'mse': {'train': train_mse, 'test': test_mse}})\n",
    "    return curves\n",
    "\n",
    "param_grid_als = {  \"k\": [20, 40, 80],\n",
    "                    \"alpha\": [40, 50],\n",
    "                    \"_lambda\": [0.0, 1e-1, 1e-2, 10]}\n",
    "              \n",
    "param_grid_gd = {   \"k\": [20, 40, 80],\n",
    "                    \"iterations\": [1000, 3000, 10000],\n",
    "                    \"learning_rate\": [0.3, 0.5],\n",
    "                    # \"beta\": [0.5, 0.9],\n",
    "                    \"_lambda\": [0.0, 1e-1, 1e-2, 10]}\n",
    "\n",
    "param_grid_sgd = {  \"k\": [20, 40, 80],\n",
    "                    \"epochs\": [2, 5, 10],\n",
    "                    \"learning_rate\": [0.003, 0.03, 0.3],\n",
    "                    # \"beta\": [0.5, 0.9],\n",
    "                    \"_lambda\": [0.0, 1e-1, 1e-2, 10]}\n",
    "\n",
    "grid_search(\"gd\", train, test, param_grid_gd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(611, 40) (9725, 40)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47568abc92f24e48827283c4901ab5e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ALS iterations completion:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb0e030cf4e41398fa8faca7666ea08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving for P:   0%|          | 0/611 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "801487e4b0dc47988fc1b1c301437a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving for Q:   0%|          | 0/9725 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iteration/epoch 1 :\n",
      "train mse: 0.05308767776742674\n",
      "iteration 1 :\n",
      "test mse: 0.04611445833901195\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0bdbbd33ecd4684b0c433c9865f8be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving for P:   0%|          | 0/611 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003b56ef743842fc9b4039b751d4dffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving for Q:   0%|          | 0/9725 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iteration/epoch 2 :\n",
      "train mse: 0.06255431122201331\n",
      "iteration 2 :\n",
      "test mse: 0.07367956821442369\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e9b6f19ef8745939438f1cc6794eaf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving for P:   0%|          | 0/611 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5bfb94d418c480fbeddd1e8b795eec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving for Q:   0%|          | 0/9725 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iteration/epoch 3 :\n",
      "train mse: 0.03721520872455137\n",
      "iteration 3 :\n",
      "test mse: 0.08265034914316866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad3758b4cbd48e9b0884de2a73a7e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving for P:   0%|          | 0/611 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d5660ca9e5443fbb699952de260800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving for Q:   0%|          | 0/9725 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iteration/epoch 4 :\n",
      "train mse: 0.030075300730605506\n",
      "iteration 4 :\n",
      "test mse: 0.08767287402669395\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2b7f59e9e14d8f892424d979ff45d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving for P:   0%|          | 0/611 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9eb20edd4545dfbbf73f274295aa6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving for Q:   0%|          | 0/9725 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iteration/epoch 5 :\n",
      "train mse: 0.026547301092553342\n",
      "iteration 5 :\n",
      "test mse: 0.09072207203582733\n"
     ]
    }
   ],
   "source": [
    "######--------- Training with ALS (Alternating Least Squares) ---------######\n",
    "\n",
    "mf = MatrixFactorisation(train, 40)\n",
    "print( np.shape(mf.P), np.shape(mf.Q) )\n",
    "P, Q = mf.als(epochs=5, solver=\"cg\", validation=test, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(611, 10) (9725, 10)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a226110d9245dda145573e252ee422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total SGD epochs completion:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07823f3c849e48b1a1813316fcfd53b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch #0 completion:   0%|          | 0/80668 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0207165849464aaabfadb66b0fad0eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch #1 completion:   0%|          | 0/80668 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2caec1a268c4453bb76d8cda094bce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch #2 completion:   0%|          | 0/80668 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf3e33287e74c05b779c8274d60c64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch #3 completion:   0%|          | 0/80668 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a30f77af7043fbb9923c20ca74313a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch #4 completion:   0%|          | 0/80668 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(611, 10)\n"
     ]
    }
   ],
   "source": [
    "######--------- Training with SGD (Stochastic Gradient Descent) ---------######\n",
    "\n",
    "mf = MatrixFactorisation(train, 10)\n",
    "print( np.shape(mf.P), np.shape(mf.Q) )\n",
    "# print( mf.P )\n",
    "P, Q = mf.sgd(epochs=5, learning_rate=0.03, validation=test, verbose=False)\n",
    "print(np.shape(P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(611, 10) (9725, 10)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee40f8f68244267bfd44192911798c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Gradient Descent progress::   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m( np\u001b[38;5;241m.\u001b[39mshape(mf\u001b[38;5;241m.\u001b[39mP), np\u001b[38;5;241m.\u001b[39mshape(mf\u001b[38;5;241m.\u001b[39mQ) )\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# print( mf.P )\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m P, Q \u001b[38;5;241m=\u001b[39m \u001b[43mmf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_lambda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# print(np.shape(P))\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[40], line 58\u001b[0m, in \u001b[0;36mMatrixFactorisation.gradient_descent\u001b[0;34m(self, iterations, learning_rate, _lambda, validation, verbose)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_test_mse(\u001b[38;5;241m0\u001b[39m, validation\u001b[38;5;241m=\u001b[39mvalidation)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(iterations), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradient Descent progress:\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 58\u001b[0m        grad_P, grad_Q, error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_lambda\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m        v_P \u001b[38;5;241m=\u001b[39m beta\u001b[38;5;241m*\u001b[39mv_P \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mbeta)\u001b[38;5;241m*\u001b[39mgrad_P   \n\u001b[1;32m     60\u001b[0m        v_Q \u001b[38;5;241m=\u001b[39m beta\u001b[38;5;241m*\u001b[39mv_Q \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mbeta)\u001b[38;5;241m*\u001b[39mgrad_Q\n",
      "Cell \u001b[0;32mIn[40], line 34\u001b[0m, in \u001b[0;36mMatrixFactorisation.gradients\u001b[0;34m(self, _lambda)\u001b[0m\n\u001b[1;32m     32\u001b[0m error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mR \u001b[38;5;241m-\u001b[39m R_predicted\n\u001b[1;32m     33\u001b[0m norm_factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mR\u001b[38;5;241m.\u001b[39mnnz  \u001b[38;5;66;03m#this factor is crucial! Can't be 1 (i.e. we can't leave the gradients unnormalised, else cost diverges!)\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m grad_P \u001b[38;5;241m=\u001b[39m norm_factor \u001b[38;5;241m*\u001b[39m (\u001b[43merror\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mQ\u001b[49m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m(_lambda\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mP)\n\u001b[1;32m     35\u001b[0m grad_Q \u001b[38;5;241m=\u001b[39m norm_factor \u001b[38;5;241m*\u001b[39m (error\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mP) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m(_lambda\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad_P, grad_Q, error\n",
      "File \u001b[0;32m~/Py_VirtualEnvs/RecSys_Env/lib/python3.10/site-packages/scipy/sparse/_matrix.py:44\u001b[0m, in \u001b[0;36mspmatrix.__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__mul__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mul_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Py_VirtualEnvs/RecSys_Env/lib/python3.10/site-packages/scipy/sparse/_base.py:580\u001b[0m, in \u001b[0;36m_spbase._mul_dispatch\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mul_vector(other\u001b[38;5;241m.\u001b[39mravel())\u001b[38;5;241m.\u001b[39mreshape(M, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m other\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m other\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m N:\n\u001b[0;32m--> 580\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mul_multivector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;66;03m# scalar value\u001b[39;00m\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mul_scalar(other)\n",
      "File \u001b[0;32m~/Py_VirtualEnvs/RecSys_Env/lib/python3.10/site-packages/scipy/sparse/_compressed.py:507\u001b[0m, in \u001b[0;36m_cs_matrix._mul_multivector\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;66;03m# csr_matvecs or csc_matvecs\u001b[39;00m\n\u001b[1;32m    506\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_sparsetools, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_matvecs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 507\u001b[0m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_vecs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m   \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "######--------- Training with Gradient Descent ---------######\n",
    "\n",
    "mf = MatrixFactorisation(train, 10)\n",
    "print( np.shape(mf.P), np.shape(mf.Q) )\n",
    "# print( mf.P )\n",
    "P, Q = mf.gradient_descent(iterations=10000, learning_rate=0.4, _lambda=0, validation=test, verbose=False)\n",
    "# print(np.shape(P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print( np.array(mf.train_mse_at_epochs)[:,1] )\n",
    "mf.plot_learning_curve(validation=True)\n",
    "# mf.plot_learning_curve(validation=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roughwork..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help = np.zeros((mf.P.shape[0], mf.Q.T.shape[1]))\n",
    "# print(np.shape(help))\n",
    "\n",
    "# for i in range(mf.P.shape[0]):\n",
    "#        for j in range(mf.Q.T.shape[1]):\n",
    "#               for k in range(mf.k):\n",
    "#                      help[i][j] += mf.P[i][k] * mf.Q.T[k][j]\n",
    "\n",
    "# print(help)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.20473836  0.64551148  0.38983446 ...  0.23257534 -0.10078407\n",
      "   0.51946697]\n",
      " [-0.03210454  0.4549741   0.20326194 ...  0.80037336  0.13764056\n",
      "   0.3716281 ]\n",
      " [ 0.15991591  0.23314564  0.71370675 ...  0.18638087  0.73911567\n",
      "   0.03055401]\n",
      " ...\n",
      " [ 0.08203674  0.766394    0.12699937 ...  0.51852963  0.69768505\n",
      "   0.53541308]\n",
      " [ 0.2986957   0.47134367  0.00843501 ...  0.36027689 -0.1028373\n",
      "   0.00712214]\n",
      " [ 0.89263219  0.64457093  0.85489007 ...  0.96491938  0.21266239\n",
      "   0.86141308]] \n",
      "\n",
      "\n",
      "\n",
      " [[ 0.18277182 -0.09247713  0.67162319 ...  0.4314283   0.58398668\n",
      "   0.56219493]\n",
      " [ 0.60960645  0.38650404  0.08310481 ...  0.53197436  0.9441766\n",
      "   0.87047294]\n",
      " [ 0.67215655  0.18874724  0.1152919  ... -0.04298182  0.08912164\n",
      "   0.51268375]\n",
      " ...\n",
      " [ 0.35018881  0.20878879  0.36529109 ...  0.7042925   0.76731649\n",
      "   0.37237964]\n",
      " [ 0.68886668  0.29020615  0.48477646 ...  0.4738425   0.36753764\n",
      "   0.03762408]\n",
      " [ 0.21515453  0.66385879  0.67220178 ...  0.89190558  0.47465063\n",
      "   0.5850365 ]]\n"
     ]
    }
   ],
   "source": [
    "# help2 = mf.P @ mf.Q.T\n",
    "print(mf.P,\"\\n\\n\\n\\n\", mf.Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1., 1., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 1., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'toarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m mf\u001b[38;5;241m.\u001b[39mP\u001b[38;5;241m.\u001b[39mdot(mf\u001b[38;5;241m.\u001b[39mQ\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m      2\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(train\u001b[38;5;241m.\u001b[39mtoarray())\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m()), \u001b[38;5;28mtype\u001b[39m(train\u001b[38;5;241m.\u001b[39mtoarray()), train\u001b[38;5;241m.\u001b[39mtoarray()\u001b[38;5;241m.\u001b[39mnonzero())\n\u001b[1;32m      4\u001b[0m mask[train\u001b[38;5;241m.\u001b[39mtoarray()\u001b[38;5;241m.\u001b[39mnonzero()] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Mask out unknown ratings as 0 for ease of comparison.\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'toarray'"
     ]
    }
   ],
   "source": [
    "predictions = mf.P.dot(mf.Q.T)\n",
    "mask = np.zeros_like(train.toarray())\n",
    "print(type(predictions.toarray()), type(train.toarray()), train.toarray().nonzero())\n",
    "mask[train.toarray().nonzero()] = 1\n",
    "\n",
    "# Mask out unknown ratings as 0 for ease of comparison.\n",
    "print(np.round(predictions.toarray() * mask, 2), \"\\n\")\n",
    "print(np.round(predictions.toarray(), 2) )\n",
    "######--------\n",
    "# predictions = mf.P.dot(mf.Q.T)\n",
    "# mask = np.zeros_like(train)\n",
    "# print(type(predictions.toarray()), type(train.toarray()), train.toarray().nonzero())\n",
    "# mask[train.nonzero()] = 1\n",
    "\n",
    "# # Mask out unknown ratings as 0 for ease of comparison.\n",
    "# print(np.round(predictions * mask, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### File saving and download utility for Colab\n",
    "\n",
    "# from google.colab import files\n",
    "\n",
    "# user_emb_df = pd.DataFrame(P)\n",
    "# user_emb_df.to_csv(\"saved_user_emb.csv\", delimiter=\"\\t\", index=True)\n",
    "# movie_emb_df = pd.DataFrame(Q)\n",
    "# movie_emb_df.to_csv(\"saved_movie_emb.csv\", delimiter=\"\\t\", index=True)\n",
    "\n",
    "# files.download(\"saved_user_emb.csv\")\n",
    "# files.download(\"saved_movie_emb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape[0]\n",
    "train.shape[0] * train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RecSys_Env",
   "language": "python",
   "name": "recsys_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
