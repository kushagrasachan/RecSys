{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System\n",
    "\n",
    "### What this project does\n",
    "### What this project doesn't do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For working on Google Colab\n",
    "# !curl -O http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
    "# !unzip ml-latest-small.zip\n",
    "# !cd ml-latest-small/\n",
    "\n",
    "# !curl -O https://files.grouplens.org/datasets/movielens/ml-10m.zip\n",
    "# !unzip ml-10m.zip\n",
    "# !cd ml-10M100K/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now, I've encountered two types of data objects in the Pandas library—DataFrames and Series, and here is a [Scaler Topics article on core components of Pandas](https://www.scaler.com/topics/pandas/core-components-of-pandas/), confirming that these two are the important ones (for single-dimensional, and two-dimensional data respectively), apart from a third object type, `Panel` (for three-dimensional data).\n",
    "\n",
    "Here's a micro-article attempting to list the organisation of files in Pandas' architecture: [Discover Pandas Library Architecture – File Hierarchy in Pandas](https://data-flair.training/blogs/pandas-library-architecture/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.read_csv(\"./ml-latest-small/ratings.csv\")\n",
    "# ratings_df = pd.read_csv(\"./ml-10M100K/ratings.dat\", delimiter='::', names=['userId', 'movieId', 'rating', 'timestamp'])\n",
    "# ratings_df = pd.read_csv(\"./anime-ratings-matrix-factorization-v-10/anime ratings dataset/rating.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100836 entries, 0 to 100835\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   userId     100836 non-null  int64  \n",
      " 1   movieId    100836 non-null  int64  \n",
      " 2   rating     100836 non-null  float64\n",
      " 3   timestamp  100836 non-null  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "ratings_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9724 movies and 610 users in the dataset\n"
     ]
    }
   ],
   "source": [
    "# num_movies = pd.DataFrame(ratings_df['movieId'].unique()).count().values[0]       #this is a tad more convoluted way\n",
    "# num_users = pd.DataFrame(ratings_df['userId'].unique()).count().values[0]\n",
    "num_movies = ratings_df['movieId'].unique().shape[0]                                #better way\n",
    "num_users = ratings_df['userId'].unique().shape[0]\n",
    "print(f\"There are {num_movies} movies and {num_users} users in the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 user IDs exceeding 610.\n",
      "There are 4334 movie IDs exceeding 9724.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {ratings_df.loc[ratings_df.userId > num_users].userId.unique().shape[0]} user IDs exceeding {num_users}.\")\n",
    "print(f\"There are {ratings_df.loc[ratings_df.movieId > num_movies].movieId.unique().shape[0]} movie IDs exceeding {num_movies}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the user IDs are contiguous, while the move IDs are not. We might have to consider making them contiguous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <td>100836.0</td>\n",
       "      <td>3.261276e+02</td>\n",
       "      <td>1.826185e+02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.770000e+02</td>\n",
       "      <td>3.250000e+02</td>\n",
       "      <td>4.770000e+02</td>\n",
       "      <td>6.100000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <td>100836.0</td>\n",
       "      <td>1.943530e+04</td>\n",
       "      <td>3.553099e+04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.199000e+03</td>\n",
       "      <td>2.991000e+03</td>\n",
       "      <td>8.122000e+03</td>\n",
       "      <td>1.936090e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <td>100836.0</td>\n",
       "      <td>3.501557e+00</td>\n",
       "      <td>1.042529e+00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.500000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <td>100836.0</td>\n",
       "      <td>1.205946e+09</td>\n",
       "      <td>2.162610e+08</td>\n",
       "      <td>828124615.0</td>\n",
       "      <td>1.019124e+09</td>\n",
       "      <td>1.186087e+09</td>\n",
       "      <td>1.435994e+09</td>\n",
       "      <td>1.537799e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count          mean           std          min           25%  \\\n",
       "userId     100836.0  3.261276e+02  1.826185e+02          1.0  1.770000e+02   \n",
       "movieId    100836.0  1.943530e+04  3.553099e+04          1.0  1.199000e+03   \n",
       "rating     100836.0  3.501557e+00  1.042529e+00          0.5  3.000000e+00   \n",
       "timestamp  100836.0  1.205946e+09  2.162610e+08  828124615.0  1.019124e+09   \n",
       "\n",
       "                    50%           75%           max  \n",
       "userId     3.250000e+02  4.770000e+02  6.100000e+02  \n",
       "movieId    2.991000e+03  8.122000e+03  1.936090e+05  \n",
       "rating     3.500000e+00  4.000000e+00  5.000000e+00  \n",
       "timestamp  1.186087e+09  1.435994e+09  1.537799e+09  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rating</th>\n",
       "      <th>4.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>3.5</th>\n",
       "      <th>4.5</th>\n",
       "      <th>2.0</th>\n",
       "      <th>2.5</th>\n",
       "      <th>1.0</th>\n",
       "      <th>1.5</th>\n",
       "      <th>0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26818</td>\n",
       "      <td>20047</td>\n",
       "      <td>13211</td>\n",
       "      <td>13136</td>\n",
       "      <td>8551</td>\n",
       "      <td>7551</td>\n",
       "      <td>5550</td>\n",
       "      <td>2811</td>\n",
       "      <td>1791</td>\n",
       "      <td>1370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rating    4.0    3.0    5.0    3.5   4.5   2.0   2.5   1.0   1.5   0.5\n",
       "count   26818  20047  13211  13136  8551  7551  5550  2811  1791  1370"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series.value_counts(ratings_df['rating']).to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(ratings_df['rating'], bins=[(i-1)/2 for i in range(0, 12)])\n",
    "# plt.hist(ratings_df['rating'], bins=[i-0.5 for i in range(-1,12)])  #for anime ratings dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId       0\n",
      "movieId      0\n",
      "rating       0\n",
      "timestamp    0\n",
      "dtype: int64 \n",
      "\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print( ratings_df.isna().sum() , \"\\n\")\n",
    "print( type(ratings_df.isna().sum()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100836"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( len(ratings_df.duplicated(subset=['userId', 'movieId'])) )\n",
    "len(np.where( ratings_df.duplicated(subset=['userId', 'movieId']) == False )[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There don't seem to be any duplicates *shruggie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 2.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy = np.zeros((3,4))\n",
    "toy[0,1] = 1\n",
    "toy[2,3] = 2\n",
    "toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2.]\n",
      "2\n",
      "(array([0, 2], dtype=int32), array([1, 3], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "toy_csc = sparse.csc_matrix(toy)\n",
    "print( toy_csc.data )\n",
    "print( toy_csc.nnz )  # nnz => no. of non-zero (entries)\n",
    "print( toy_csc.nonzero() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 4.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_csc.power(2).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "## This was an attempt to write a general function to make IDs contiguous ##\n",
    "############################################################################\n",
    "\n",
    "# def make_id_contiguous(df:pd.DataFrame, id:str):\n",
    "#        old_new_id = np.zeros(df[id].max()+1)\n",
    "#        for new_id, old_id in enumerate(df[id].unique()):\n",
    "#               old_new_id[old_id] = new_id\n",
    "              \n",
    "#        import re\n",
    "#        RE_WORDS = re.compile(r'''\n",
    "#                      # Find words in a string. Order matters!\n",
    "#                      [A-Z]+(?=[A-Z][a-z]) |  # All upper case before a capitalized word\n",
    "#                      [A-Z]?[a-z]+ |  # Capitalized words / all lower case\n",
    "#                      [A-Z]+ |  # All upper case\n",
    "#                      \\d+  # Numbers\n",
    "#                      ''', re.VERBOSE)\n",
    "#        id_split = RE_WORDS.findall(id)\n",
    "#        print(id_split)\n",
    "#        print(np.where(id_split == 'Id'))\n",
    "#        # id_split[np.where(id_split == 'Id')] = 'newId'\n",
    "#        new_id_name = \"\".join(i for i in id_split)\n",
    "\n",
    "#        df[new_id_name] = old_new_id[df[id]]\n",
    "#        df = df.astype({new_id_name: 'int64'})\n",
    "#        print( df.head(), \"\\n\" )\n",
    "#        return old_new_id\n",
    "\n",
    "# make_id_contiguous(ratings_df, 'movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating  timestamp  userNewId\n",
      "0       1        1     4.0  964982703          0\n",
      "1       1        3     4.0  964981247          0\n",
      "2       1        6     4.0  964982224          0\n",
      "3       1       47     5.0  964983815          0\n",
      "4       1       50     5.0  964982931          0 \n",
      "\n",
      "       userId  userNewId\n",
      "22684     156        155\n",
      "22685     156        155\n",
      "22686     156        155\n",
      "22687     156        155\n",
      "22688     156        155\n",
      "...       ...        ...\n",
      "23077     156        155\n",
      "23078     156        155\n",
      "23079     156        155\n",
      "23080     156        155\n",
      "23081     156        155\n",
      "\n",
      "[398 rows x 2 columns] \n",
      "\n",
      "There are 610 users and correspondingly 610.0 contiguous user IDs now\n"
     ]
    }
   ],
   "source": [
    "user_old_new_id = np.zeros(ratings_df[\"userId\"].max()+1)\n",
    "for new_id, old_id in enumerate(ratings_df['userId'].unique()):\n",
    "       user_old_new_id[old_id] = new_id\n",
    "       \n",
    "ratings_df['userNewId'] = user_old_new_id[ratings_df['userId']]\n",
    "ratings_df = ratings_df.astype({'userNewId': 'int64'})\n",
    "\n",
    "print( ratings_df.head(), \"\\n\" )\n",
    "# now just to check that we did it correctly, a movieId should be mapped to the same movieNewId\n",
    "print( ratings_df.loc[ratings_df.userId == 156][['userId', 'userNewId']], \"\\n\" ) \n",
    "print(f\"There are {num_users} users and correspondingly {max(user_old_new_id)+1} contiguous user IDs now\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating  timestamp  userNewId  movieNewId\n",
      "0       1        1     4.0  964982703          0           0\n",
      "1       1        3     4.0  964981247          0           1\n",
      "2       1        6     4.0  964982224          0           2\n",
      "3       1       47     5.0  964983815          0           3\n",
      "4       1       50     5.0  964982931          0           4 \n",
      "\n",
      "       movieId  movieNewId\n",
      "17007      156        4463\n",
      "96137      156        4463\n",
      "97391      156        4463 \n",
      "\n",
      "There are 9724 movies and correspondingly 9724.0 contiguous movie IDs now\n"
     ]
    }
   ],
   "source": [
    "movie_old_new_id = np.zeros(ratings_df[\"movieId\"].max()+1)\n",
    "for new_id, old_id in enumerate(ratings_df['movieId'].unique()):\n",
    "       movie_old_new_id[old_id] = new_id\n",
    "       \n",
    "ratings_df['movieNewId'] = movie_old_new_id[ratings_df['movieId']]\n",
    "ratings_df = ratings_df.astype({'movieNewId': 'int64'})\n",
    "\n",
    "print( ratings_df.head(), \"\\n\" )\n",
    "# now just to check that we did it correctly, a movieId should be mapped to the same movieNewId\n",
    "print( ratings_df.loc[ratings_df.movieId == 156][['movieId', 'movieNewId']], \"\\n\" ) \n",
    "print(f\"There are {num_movies} movies and correspondingly {max(movie_old_new_id)+1} contiguous movie IDs now\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       userId  movieId  rating   timestamp  userNewId  movieNewId\n",
      "0         509     7347     3.0  1435994597        508        4285\n",
      "1         326    71462     4.0  1322252335        325        5629\n",
      "2          57     2115     3.0   965798155         56         134\n",
      "3         610     1127     4.0  1479544102        609          66\n",
      "4         462     2409     2.0  1174438249        461        1172\n",
      "...       ...      ...     ...         ...        ...         ...\n",
      "80663      42     4005     4.0   996259059         41        1873\n",
      "80664     364      141     4.0   869443367        363         524\n",
      "80665     480     6867     4.0  1179163171        479        2240\n",
      "80666       6      981     3.0   845556567          5         712\n",
      "80667     103     6711     5.0  1431957425        102        2046\n",
      "\n",
      "[80668 rows x 6 columns]\n",
      "       userId  movieId  rating   timestamp  userNewId  movieNewId\n",
      "0         432    77866     4.5  1335139641        431        4730\n",
      "1         288      474     3.0   978465565        287         474\n",
      "2         599     4351     3.0  1498524542        598        2631\n",
      "3          42     2987     4.0   996262677         41         194\n",
      "4          75     1610     4.0  1158989841         74         727\n",
      "...       ...      ...     ...         ...        ...         ...\n",
      "20163     380     5048     2.0  1494268065        379         279\n",
      "20164     434    54272     3.5  1270606860        433        1269\n",
      "20165     226     5989     4.5  1162428551        225         765\n",
      "20166     607     1320     3.0   963080497        606        2750\n",
      "20167     567      750     3.0  1525287719        566         722\n",
      "\n",
      "[20168 rows x 6 columns]\n",
      "(80668, 6) (20168, 6)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(ratings_df, test_size=0.2, random_state=42)  #setting random_state ensures consistent splitting every time\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "print(train_df)\n",
    "print(test_df)\n",
    "print( np.shape(train_df), np.shape(test_df) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we've chosen to make the movie IDs contiguous by mapping them to new ones, splitting the DataFrame makes creating smaller-dimensional matrix representations of the training or test sets difficult, because, say, the indices chosen in the training set can still lie out of bounds of its smaller matrix's size (similar logic holds for the test set).\n",
    "\n",
    "Instead, let's just work with the full ratings matrix, with the test entries zeroed out in the training matrix (and vice versa), which wouldn't be a bother to the memory anyway because we're using a sparse representation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 80668 & 20168 non-zero elements in the train and test sparse matrices respectively.\n",
      " 611 9725\n"
     ]
    }
   ],
   "source": [
    "train = sparse.csc_matrix( (train_df['rating'].values, (train_df['userNewId'].values, train_df['movieNewId'].values)),\\\n",
    "                                 shape=(num_users+1, num_movies+1) )\n",
    "test = sparse.csc_matrix(  (test_df['rating'].values, (test_df['userNewId'].values, test_df['movieNewId'].values)),\\\n",
    "                                 shape=(num_users+1, num_movies+1))\n",
    "\n",
    "print(f\"There are {train.nnz} & {test.nnz} non-zero elements in the train and test sparse matrices respectively.\\n\", test.shape[0],train.shape[1] )\n",
    "# train.to_dense()\n",
    "# print( train )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemme check once that the test and train matrix elements are indeed mutually exclusive (zero, non-zero in their matrices respectively).\n",
    "\n",
    "The cell below seems to show all's good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in zip(test.nonzero()[0], test.nonzero()[1]):\n",
    "       if( train[i[0],i[1]] != 0 ):\n",
    "              print(\"Hah!\")\n",
    "for i in zip(train.nonzero()[0], train.nonzero()[1]):\n",
    "       if( test[i[0],i[1]] != 0 ):\n",
    "              print(\"Hah!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print( np.sort(train_df['userId'].values) )\n",
    "# print( mf.p_nnz_idx, \"\\n\" )\n",
    "\n",
    "# print( np.sort(train_df['movieNewId'].values) )\n",
    "# print( np.sort(mf.q_nnz_idx ) )\n",
    "# print( np.sort(train_df['userId'].values) == mf.p_nnz_idx )\n",
    "# print( np.sort(train_df['movieNewId'].values) == np.sort(mf.q_nnz_idx), \"\\n\" )\n",
    "\n",
    "# print( np.where( np.sort(train_df['userId'].values) != train.nonzero()[0]) )\n",
    "# print( np.where( np.sort(train_df['movieNewId'].values) != np.sort( train.nonzero()[1]) ) )\n",
    "# print( np.where( np.sort(train_df['movieNewId'].values) != np.sort(mf.q_nnz_idx)) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm, so the row indices seem to be all good, ~~but the column indices are playing foul.~~ as do the column indices.\n",
    "\n",
    "Wasted quite the time pursuing this!\n",
    "\n",
    "We have used the list `train_df['movieNewId'].values` as the column indices needed to generate R, but upon querying back these column indices, ~~they're coming out wrong!~~\n",
    "Previously, I wasn ony sorting the `train_df['movieNewId'].values` list, and not the list `mf.q_nnz_idx` for comparison. Upon sorting both, they indeed come out to be the same.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorisation Class\n",
    "Below, I furnish a Matrix Factorisation Python class that implements:\n",
    "- gradient descent\n",
    "- (pending) gradient descent with user and item biases\n",
    "- (pending) sgd\n",
    "- (pending) ALS\n",
    "to learn the embeddings.\n",
    "\n",
    "My current implementation of gradient descent considers the loss function for explicit ratings, i.e. solely over observed values.\n",
    "Still need to implement the Koren et al. approach capturing implicit ratings from the entire matrix.\n",
    "\n",
    "The regularised loss I've used for explicit ratings: $$L(R, P, Q) = \\frac{1}{N}\\underset{(i,j):r_{ui}≠Nan}{\\sum} (r_{ui} - p_u^T\\cdot q_i)^2 + \\lambda(\\sum_u{||p_u||^2} + \\sum_i{||q_i||^2})$$\n",
    "It's a squared error (SE) loss function with regularisation terms. I wonder how using the Mean SE or RMSE would change the behaviour. ~~Conceptually, it shouldn't..~~ Oh how pathetically wrong I was! Not providing the required normalisation on the gradient terms just blew the cost up! I wonder why not providing the normalisation to the gradient calculation blows up the cost. The two seem unrelated, except, not!\n",
    "\n",
    "Still need to add the user and item bias terms to SGD and GD\n",
    "\n",
    "I could provide an option for choosing to provide explicit or implicit data. That way, when one chooses explicit data, I can internally use either of sgd or gd as default (still need to choose which), and when one chooses implicit data, I can choose either ALS or CG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorisation():\n",
    "       def __init__(self, R:sparse.csc_matrix, k:int, verbose:bool=False ):\n",
    "              self.R = R           # R is the \"ratings\" matrix to be factorised\n",
    "              self.k = k           # hyperparameter k is the number of latent factors desired in the factorised embeddings\n",
    "              self.m, self.n = R.shape\n",
    "              self.P = np.random.rand(self.m, k)        # initialising the first factor embedding (of \"users\")\n",
    "              self.Q = np.random.rand(self.n, k)        # initialising the second factor embedding (of \"items\")\n",
    "              self.p_nnz_idx, self.q_nnz_idx = R.nonzero()        # row and col indices in R matrix respectively, of non-zero elements\n",
    "              self.train_mse_at_epochs = []\n",
    "              self.test_mse_at_epochs = []\n",
    "              self.verbose = verbose\n",
    "              self.verbose_epoch_intvl = 50\n",
    "\n",
    "       def __predict_observed(self):\n",
    "              \"\"\"\n",
    "              Returns predicted values as a sparse matrix, corresponding to indices of non-zero elements in matrix R to be factorised\n",
    "\n",
    "              Avoids constructing a dense prediction matrix produced via naïve dense matrix multiplication of factors.\n",
    "              Instead, produces predicted values by multiplying only the requisite factor vectors corresponding to non-zero entries in R.\n",
    "              \"\"\"\n",
    "              R_predicted = np.sum( np.multiply(self.P[self.p_nnz_idx], self.Q[self.q_nnz_idx]), axis=1 )       #calculating the products only for the nonzero \"observed\" rating entries: explicit MF\n",
    "              R_predicted = sparse.csc_matrix( (R_predicted, (self.p_nnz_idx, self.q_nnz_idx)), shape=(self.m,self.n))              \n",
    "              # R_predicted = self.P @ self.Q.T\n",
    "              # R_predicted = sparse.csc_matrix(R_predicted)\n",
    "              return R_predicted\n",
    "\n",
    "       def gradients(self, _lambda):\n",
    "              \"\"\"\n",
    "              Returns l2 gradients w.r.t the elements of the embedding vectors, along with the prediction errors\n",
    "              \"\"\"\n",
    "              R_predicted = self.__predict_observed()\n",
    "              error = self.R - R_predicted\n",
    "              norm_factor = -2 / self.m  #this factor is crucial! Can't be 1 (i.e. we can't leave the gradients unnormalised, else cost diverges!)\n",
    "              grad_P = norm_factor * (error*self.Q) + 2*(_lambda*self.P)\n",
    "              grad_Q = norm_factor * (error.T*self.P) + 2*(_lambda*self.Q)\n",
    "              return grad_P, grad_Q, error\n",
    "\n",
    "       def gradient_descent(self, iterations=2000, learning_rate = 0.3, _lambda=0.0002, validation:sparse.csc_matrix=None, verbose=False):\n",
    "              \"\"\"\n",
    "              Returns factor matrices for explicit data matrix by learning their entries via full-batch gradient descent.\n",
    "\n",
    "              Returned factor matrices P,Q represent user and item embeddings, for explicit ratings data R.\n",
    "                     R = P.Q^T\n",
    "\n",
    "              Optionally provide a sparse matrix with validation data, to compute the validation performance (measured by mse) over time\n",
    "              \"\"\"\n",
    "              self.verbose = verbose\n",
    "\n",
    "              grad_P, grad_Q, error = self.gradients(self.R, _lambda)\n",
    "              v_P = grad_P\n",
    "              v_Q = grad_Q\n",
    "              beta = 0.8    # momentum constant\n",
    "              train_mse = error.power(2).sum()/self.R.shape[0]\n",
    "              # print(\"train mse:\", train_mse)\n",
    "              self.train_mse_at_epochs.append( [1, train_mse] )\n",
    "              for i in range(iterations):\n",
    "                     grad_P, grad_Q, error = self.gradients(_lambda)\n",
    "                     v_P = beta*v_P + (1-beta)*grad_P   \n",
    "                     v_Q = beta*v_Q + (1-beta)*grad_Q\n",
    "                     self.P = self.P - learning_rate*v_P       # Grad Desc update rule\n",
    "                     self.Q = self.Q - learning_rate*v_Q       # Grad Desc update rule\n",
    "                     # print(\"train mse:\", error.power(2).sum()/self.R.shape[0] )  #print mse at each iteration\n",
    "                     if(not (i+1)%self.verbose_epoch_intvl):\n",
    "                            self.save_train_mse(i, error)\n",
    "                            self.save_test_mse(i, validation=validation)\n",
    "              return self.P, self.Q\n",
    "\n",
    "       def save_train_mse(self, i, error):\n",
    "              train_mse = error.power(2).sum()/self.R.shape[0]\n",
    "              self.train_mse_at_epochs.append( [i+1, train_mse])\n",
    "              if(self.verbose):\n",
    "                     print(\"\\niteration/epoch\", i+1, \":\")\n",
    "                     print(\"train mse:\", train_mse)\n",
    "\n",
    "       def save_test_mse(self, i, validation=None):\n",
    "              if(validation != None):\n",
    "                     valdn_p_nnz_idx, valdn_q_nnz_idx = validation.nonzero()\n",
    "                     valdn_predicted = np.sum( np.multiply(self.P[valdn_p_nnz_idx], self.Q[valdn_q_nnz_idx]), axis=1 )       #calculating the products only for the nonzero \"observed\" rating entries\n",
    "                     valdn_predicted = sparse.csc_matrix( (valdn_predicted, (valdn_p_nnz_idx, valdn_q_nnz_idx)), shape=(self.m,self.n))\n",
    "                     valdn_error = validation - valdn_predicted\n",
    "                     test_mse = valdn_error.power(2).sum()/self.R.shape[0]\n",
    "                     self.test_mse_at_epochs.append([i+1, test_mse])\n",
    "                     if(self.verbose):\n",
    "                            print(\"iteration\", i+1, \":\")\n",
    "                            print(\"test mse:\", test_mse)\n",
    "\n",
    "       def sgd(self, epochs=30, learning_rate=0.003, _lambda=0.0002, verbose=False):\n",
    "              \"\"\"\n",
    "              Returns factor matrices for explicit data matrix by learning their entries via stochastic gradient descent.\n",
    "\n",
    "              Returned factor matrices P,Q represent user and item embeddings, for explicit ratings data R.\n",
    "                     R = P.Q^T\n",
    "              \"\"\"\n",
    "              self.verbose = verbose\n",
    "              beta = 0.8\n",
    "\n",
    "              num_samples = len(self.p_nnz_idx)\n",
    "              training_indices = np.arange(num_samples)\n",
    "              # I couldn't have shuffled the array p_nnz_idx itself, cuz that would require shuffling q_nnx_idx in a corresponding manner\n",
    "\n",
    "              # with tqdm(total=100) as prog_bar:\n",
    "              for epoch in tqdm(range(epochs), desc=\"SGD epoch completion: \"):\n",
    "                     np.random.shuffle(training_indices)       #stochasticity must be ensured properly!\n",
    "                     for i in tqdm(training_indices, desc=f\"Finishing epoch: \"):         #We need to update all users and items at least once in each iteration\n",
    "                            p_idx = self.p_nnz_idx[i]\n",
    "                            q_idx = self.q_nnz_idx[i]\n",
    "\n",
    "                            R_ij = self.R[p_idx, q_idx]\n",
    "                            P_i = self.P[p_idx]\n",
    "                            Q_j = self.Q[q_idx]\n",
    "\n",
    "                            R_predicted_ij = P_i.dot(Q_j.T)\n",
    "                            error_ij = R_ij - R_predicted_ij\n",
    "                            grad_P_i = -2*(error_ij * Q_j) + 2*(_lambda * self.P[p_idx])\n",
    "                            grad_Q_j = -2*(error_ij * P_i) + 2*(_lambda * self.Q[q_idx])\n",
    "\n",
    "                            v_P_i = beta*v_P_i + (1-beta)*grad_P_i if epoch!=0 else grad_P_i\n",
    "                            v_Q_j = beta*v_Q_j + (1-beta)*grad_Q_j if epoch!=0 else grad_Q_j\n",
    "       \n",
    "                            self.P[p_idx] -= learning_rate * v_P_i\n",
    "                            self.Q[q_idx] -= learning_rate * v_Q_j\n",
    "                            # self.P[p_idx] -= learning_rate* grad_P_i\n",
    "                            # self.Q[q_idx] -= learning_rate* grad_Q_j\n",
    "\n",
    "                     if(not (epoch+1)%(self.verbose_epoch_intvl/10)):\n",
    "                            R_predicted = np.sum( np.multiply(self.P[self.p_nnz_idx], self.Q[self.q_nnz_idx]), axis=1 )       #calculating the products only for the nonzero \"observed\" rating entries\n",
    "                            R_predicted = sparse.csc_matrix( (R_predicted, (self.p_nnz_idx, self.q_nnz_idx)), shape=(self.m,self.n))\n",
    "                            error = self.R - R_predicted\n",
    "                            self.save_train_mse(epoch, error)\n",
    "                            # self.save_test_mse(i, validation=validation)\n",
    "              return self.P, self.Q\n",
    "\n",
    "       def als(self, epochs=10, alpha=40, _lambda=10, solver=\"cg\", verbose=False):\n",
    "              \"\"\"\n",
    "              Returns factor matrices for implicit data matrix by learning their entries via Alternating Least Squares method.\n",
    "\n",
    "              Returned factor matrices P,Q represent user and item embeddings, for binarised ratings data Phi derived from R.\n",
    "                     Phi[p,q] =    { 0    for R[p,q]=0\n",
    "                                   { 1    for R[p,q]>0\n",
    "              &      Phi = P.Q^T\n",
    "\n",
    "              Uses scipy.sparse.linalg's spsolve as its solver\n",
    "              \"\"\"\n",
    "              ## should I be making the following tradeoff for precomputed memory, to speed up implementation?\n",
    "              # Cp_array = []\n",
    "              # Cq_array = []\n",
    "              # for p in range(self.m):\n",
    "              #        C_p = sparse.diags(self.R[p].toarray(), [0])\n",
    "              #        Cp_array.append(C_p)\n",
    "              # for q in range(self.n):\n",
    "              #        C_q = sparse.diags(self.R[q].toarray(), [0])\n",
    "              #        Cq_array.append(C_q)\n",
    "              self.verbose = verbose\n",
    "              lambda_eye = _lambda * sparse.eye(self.k)\n",
    "\n",
    "              P = sparse.csc_matrix(self.P)\n",
    "              Q = sparse.csc_matrix(self.Q)\n",
    "\n",
    "              # the memory for this loop can further be optimised by eliminating the two similar loops with appropriate conditioning\n",
    "              for i in tqdm(range(epochs), desc=\"ALS iterations completion: \"):\n",
    "                     # Q = sparse.csc_matrix(self.Q)\n",
    "                     QTQ = Q.T.dot(Q)         #precomputation of Q.T.dot(Q) for all elements of P\n",
    "                     for p in tqdm(range(self.m), desc=\"Solving for P: \", leave=True):\n",
    "                            R_p = self.R[p].toarray()\n",
    "                            CpI = sparse.diags(alpha * R_p, [0])      #This acts as the (C^u - I) matrix in literature\n",
    "                            QTCpIQ = Q.T.dot(CpI).dot(Q)\n",
    "                            A = (QTQ + QTCpIQ) + lambda_eye\n",
    "\n",
    "                            phi = R_p.copy()\n",
    "                            phi[np.where(phi != 0)] = 1.0\n",
    "                            b = Q.T.dot(CpI + sparse.eye(self.n)).dot(sparse.csc_matrix(phi).T)       # why the last transpose on phi though?\n",
    "\n",
    "                            if(solver == \"lu\"):\n",
    "                                   P[p] = sparse.linalg.spsolve(A, b)\n",
    "                                   # self.P[p] = sparse.linalg.spsolve(A, b)\n",
    "                            if(solver == \"cg\"):\n",
    "                                   P[p], exitcode = sparse.linalg.cg(A, b.toarray())\n",
    "                                   if(exitcode):\n",
    "                                          print(f\"Conjugate Gradient Method couldn't converge properly, exited with convergence exitcode {exitcode}\")\n",
    "                     \n",
    "                     # P = sparse.csc_matrix(self.P)\n",
    "                     PTP = P.T.dot(P)         #precomputation of P.T.dot(P) for all elements of Q\n",
    "                     for q in tqdm(range(self.n), desc=\"Solving for Q: \"):\n",
    "                            R_q = self.R[:,q].T.toarray()\n",
    "                            CqI = sparse.diags(alpha * R_q, [0])      #This acts as the (C^u - I) matrix in literature\n",
    "                            PTCqIP = P.T.dot(CqI).dot(P)\n",
    "                            A = (PTP + PTCqIP) + lambda_eye\n",
    "\n",
    "                            phi = R_q.copy()\n",
    "                            phi[np.where(phi != 0)] = 1.0\n",
    "                            b = P.T.dot(CqI + sparse.eye(self.m)).dot(sparse.csc_matrix(phi).T)       # why the last transpose on phi though?\n",
    "\n",
    "                            if(solver == \"lu\"):\n",
    "                                   Q[q] = sparse.linalg.spsolve(A, b)\n",
    "                                   # self.Q[q] = sparse.linalg.spsolve(A, b)\n",
    "                            if(solver == \"cg\"):\n",
    "                                   Q[q], exitcode = sparse.linalg.cg(A, b.toarray())\n",
    "                                   if(exitcode):\n",
    "                                          print(f\"Conjugate Gradient Method couldn't converge properly, exited with convergence exitcode {exitcode}\")\n",
    "\n",
    "                     # Phi_predicted = np.sum( np.multiply(self.P[self.p_nnz_idx], self.Q[self.q_nnz_idx]), axis=1 )       #calculating the products only for the nonzero \"observed\" rating entries\n",
    "                     # Phi_predicted = sparse.csc_matrix( (Phi_predicted, (self.p_nnz_idx, self.q_nnz_idx)), shape=(self.m,self.n))\n",
    "                     Phi_predicted = np.sum( np.multiply(P.toarray()[self.p_nnz_idx], Q.toarray()[self.q_nnz_idx]), axis=1 )       #calculating the products only for the nonzero \"observed\" rating entries\n",
    "                     Phi_predicted = sparse.csc_matrix( (Phi_predicted, (self.p_nnz_idx, self.q_nnz_idx)), shape=(self.m,self.n))\n",
    "                     Phi = self.R\n",
    "                     Phi[Phi.nonzero()] = 1.0\n",
    "                     error = Phi - Phi_predicted\n",
    "                     self.save_train_mse(i, error)\n",
    "              self.P = P\n",
    "              self.Q = Q\n",
    "              return self.P, self.Q\n",
    "\n",
    "       def plot_learning_curve(self, validation=None):\n",
    "              if(validation != None):\n",
    "                     test_mse_arr = np.array(self.test_mse_at_epochs)\n",
    "                     plt.plot(test_mse_arr[:,0], test_mse_arr[:,1], label='Test')\n",
    "              train_mse_arr = np.array(self.train_mse_at_epochs)\n",
    "              plt.plot(train_mse_arr[:,0], train_mse_arr[:,1], label='Train')\n",
    "              plt.xticks(fontsize=16)\n",
    "              plt.yticks(fontsize=16)\n",
    "              plt.xlabel('iterations', fontsize=12)\n",
    "              plt.ylabel('MSE', fontsize=12)\n",
    "              plt.legend(loc='best', fontsize=9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(611, 40) (9725, 40)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4ad6ec6bcb4e6ea83ab586b2d6f946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ALS iterations completion:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e9b97a3f6984d9f914a5e7a7e0081d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving for P:   0%|          | 0/611 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb22854a1a16459c90cd71cc2d89d111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving for Q:   0%|          | 0/9725 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iteration/epoch 1 :\n",
      "train mse: 20.999426257296133\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc9b4efab5a4825994e8263f27cce57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving for P:   0%|          | 0/611 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8bdd2074fda468b9d93278ec6184921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving for Q:   0%|          | 0/9725 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iteration/epoch 2 :\n",
      "train mse: 7.014405098211773\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54b1e41da3d467e90cfa667ea0a2360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving for P:   0%|          | 0/611 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e255bbe11d741ba91adf45e0e728a0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving for Q:   0%|          | 0/9725 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iteration/epoch 3 :\n",
      "train mse: 4.98455425168618\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffcf4b0fccdb47d294b5cc926fdaa5d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving for P:   0%|          | 0/611 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d45c97716d6b4325b5364269ebdaf58c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving for Q:   0%|          | 0/9725 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iteration/epoch 4 :\n",
      "train mse: 4.172730007233119\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8529e0ef7780483d84c18c94c35954f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving for P:   0%|          | 0/611 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aac1e9c9fe54606aee139442ac535be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving for Q:   0%|          | 0/9725 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iteration/epoch 5 :\n",
      "train mse: 3.717601008610088\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d5aa1b0052408281c130e0be2cdbbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving for P:   0%|          | 0/611 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a9e8578b2c4e5bac4fc7f2ff366c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving for Q:   0%|          | 0/9725 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iteration/epoch 6 :\n",
      "train mse: 3.4160149334637557\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97294110ac82464285b7632fda86e4cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving for P:   0%|          | 0/611 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27fcb0c8d8fd49559d6a710682c54ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving for Q:   0%|          | 0/9725 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iteration/epoch 7 :\n",
      "train mse: 3.1967135516039136\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48a617426ea4acebe475a2088fd59ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving for P:   0%|          | 0/611 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "794c5beb82f145de90ee7f7d4ab1f24a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving for Q:   0%|          | 0/9725 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iteration/epoch 8 :\n",
      "train mse: 3.027995315364981\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f4007361f3456fa459314649661704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving for P:   0%|          | 0/611 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "972b7f05e8ee419b91cf0cb8f62d1d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving for Q:   0%|          | 0/9725 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iteration/epoch 9 :\n",
      "train mse: 2.893324895510889\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001ec8593a6c49f281df15cd6dc6f167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving for P:   0%|          | 0/611 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c163c4680a74ec984992b03355a6f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving for Q:   0%|          | 0/9725 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iteration/epoch 10 :\n",
      "train mse: 2.7831247153883703\n"
     ]
    }
   ],
   "source": [
    "mf = MatrixFactorisation(train, 40)\n",
    "print( np.shape(mf.P), np.shape(mf.Q) )\n",
    "P, Q = mf.als(solver=\"cg\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(611, 10) (9725, 10)\n"
     ]
    }
   ],
   "source": [
    "mf = MatrixFactorisation(train, 10)\n",
    "print( np.shape(mf.P), np.shape(mf.Q) )\n",
    "# print( mf.P )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iteration/epoch 5 :\n",
      "train mse: 83.09331615351753\n",
      "\n",
      "iteration/epoch 10 :\n",
      "train mse: 72.79574992151512\n",
      "\n",
      "iteration/epoch 15 :\n",
      "train mse: 64.25545147251358\n",
      "\n",
      "iteration/epoch 20 :\n",
      "train mse: 58.183056203614726\n",
      "\n",
      "iteration/epoch 25 :\n",
      "train mse: 53.31928838902393\n",
      "\n",
      "iteration/epoch 30 :\n",
      "train mse: 49.98963478700182\n",
      "\n",
      "iteration/epoch 35 :\n",
      "train mse: 47.38552314481957\n",
      "\n",
      "iteration/epoch 40 :\n",
      "train mse: 46.07747934591072\n",
      "\n",
      "iteration/epoch 45 :\n",
      "train mse: 44.58463557722569\n",
      "\n",
      "iteration/epoch 50 :\n",
      "train mse: 42.89514270391427\n",
      "\n",
      "iteration/epoch 55 :\n",
      "train mse: 42.45748471494602\n",
      "\n",
      "iteration/epoch 60 :\n",
      "train mse: 41.40558263545444\n",
      "\n",
      "iteration/epoch 65 :\n",
      "train mse: 40.632415973855935\n",
      "\n",
      "iteration/epoch 70 :\n",
      "train mse: 39.61179790511118\n",
      "\n",
      "iteration/epoch 75 :\n",
      "train mse: 39.52759215675407\n",
      "\n",
      "iteration/epoch 80 :\n",
      "train mse: 38.47094051221577\n",
      "\n",
      "iteration/epoch 85 :\n",
      "train mse: 38.28939865845357\n",
      "\n",
      "iteration/epoch 90 :\n",
      "train mse: 37.70902552616321\n",
      "\n",
      "iteration/epoch 95 :\n",
      "train mse: 37.44939414158219\n",
      "\n",
      "iteration/epoch 100 :\n",
      "train mse: 37.34323969843039\n",
      "(611, 10)\n"
     ]
    }
   ],
   "source": [
    "P, Q = mf.sgd(epochs=100, learning_rate=0.03, verbose=True)\n",
    "print(np.shape(P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(611, 10) (9725, 10)\n"
     ]
    }
   ],
   "source": [
    "mf = MatrixFactorisation(train, 10)\n",
    "print( np.shape(mf.P), np.shape(mf.Q) )\n",
    "# print( mf.P )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iteration/epoch 50 :\n",
      "train mse: 81.68773059328453\n",
      "iteration 50 :\n",
      "test mse: 27.66804778641565\n",
      "\n",
      "iteration/epoch 100 :\n",
      "train mse: 70.40378845794781\n",
      "iteration 100 :\n",
      "test mse: 28.36181768450393\n",
      "\n",
      "iteration/epoch 150 :\n",
      "train mse: 60.52374349553295\n",
      "iteration 150 :\n",
      "test mse: 29.67463014745175\n",
      "\n",
      "iteration/epoch 200 :\n",
      "train mse: 53.24056589510223\n",
      "iteration 200 :\n",
      "test mse: 30.913172472606924\n",
      "\n",
      "iteration/epoch 250 :\n",
      "train mse: 48.21880618255489\n",
      "iteration 250 :\n",
      "test mse: 31.924692159794752\n",
      "\n",
      "iteration/epoch 300 :\n",
      "train mse: 44.65527413615498\n",
      "iteration 300 :\n",
      "test mse: 32.76444635377466\n",
      "\n",
      "iteration/epoch 350 :\n",
      "train mse: 42.01790762580858\n",
      "iteration 350 :\n",
      "test mse: 33.48648001319414\n",
      "\n",
      "iteration/epoch 400 :\n",
      "train mse: 39.99222992960685\n",
      "iteration 400 :\n",
      "test mse: 34.12830669943971\n",
      "\n",
      "iteration/epoch 450 :\n",
      "train mse: 38.38913933098061\n",
      "iteration 450 :\n",
      "test mse: 34.71506554118437\n",
      "\n",
      "iteration/epoch 500 :\n",
      "train mse: 37.09081562238351\n",
      "iteration 500 :\n",
      "test mse: 35.2622132301113\n"
     ]
    }
   ],
   "source": [
    "P, Q = mf.gradient_descent(iterations=500, learning_rate=0.4, _lambda=0, validation=test, verbose=True)\n",
    "# print(np.shape(P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAG6CAYAAADKywh7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABWyUlEQVR4nO3deXxTVf438M9N2qZ7uu+lQKEUWsQios8AIoobILKMIDhAEUYcfi6juNAREIUfPI6KCiougyyKIwpUQXwQiuwo0Ck4lq0FWlrWbjRpmzbrff5oExq7l7Q3y+f9euVFcu+5J9+A0g/nnJwriKIogoiIiIhumkzqAoiIiIicBYMVERERkY0wWBERERHZCIMVERERkY0wWBERERHZCIMVERERkY0wWBERERHZiJvUBbgak8mEy5cvw8/PD4IgSF0OERERtYIoiqioqEBUVBRksqbHpRisOtnly5cRGxsrdRlERETUDoWFhYiJiWnyPINVJ/Pz8wNQ+wfj7+8vcTVERETUGmq1GrGxsZaf401hsOpk5uk/f39/BisiIiIH09IyHi5eJyIiIrIRBisiIiIiG+FUIBERkYswmUzQ6XRSl2G33N3dIZfLb6oPBisiIiIXoNPpkJeXB5PJJHUpdi0gIAARERHt3hKJwYqIiMjJiaKIK1euQC6XIzY2ttl9mFyVKIrQaDQoKioCAERGRrarHwYrIiIiJ2cwGKDRaBAVFQVvb2+py7FbXl5eAICioiKEhYW1a1qQkZWIiMjJGY1GAICHh4fEldg/c/DU6/Xtup7BioiIyEXwVmotu9nfIwYrIiIiIhthsCIiIiKnUlBQAF9fX6hUqk5/bwYrIiIikpyvr6/lIZfLoVAoLK8feuihNvXVpUsXVFZWQqlUdlC1TeO3AomIiEhylZWVlud33303xowZg7///e8N2hkMBsjlcrtdL8YRKydhMok4V1yJkkqt1KUQEZGdE0URGp2h0x6iKN5UvYIg4IMPPkBycjJ8fHxQWVmJZcuWoWfPnvDz80N8fDw++OADS/v8/HwIgoDy8nIAQGpqKv7617/iscceg5+fH3r16oU9e/bcVE1N4YiVk/ifr7Lw/7KvYuHDfZA6qJvU5RARkR2r1hvRZ8FPnfZ+J994AN4eNxc5vvrqK+zYsQPBwcFwd3dHXFwcfv75Z8TExGDPnj0YMWIEUlJSMGjQoEav37BhA7Zs2YL169dj6dKlSE1NRX5+/k3V1BiOWDmJnuF+AIDsy2qJKyEiIrK9l19+GVFRUVAoFJDJZBg/fjxiY2MhCAKGDRuGBx54oNlRqBEjRuDuu++GXC7H9OnTceHCBZSWltq8To5YOYnkKH8AQPalzv8GBBERORYvdzlOvvFAp77fzerSpYvV6/Xr1+Odd95Bfn4+TCYTNBoNunVresYmIiLC8tzHxwcAUFFRgeDg4JuurT4GKyeRHF37zYfcokrU6I3wtMF/xERE5JwEQbjpqbnOVv/+hgUFBZg2bRq2b9+Ou+++G25ubhgzZsxNr+WyBU4FOolIpScCvd1hNInIuVYhdTlEREQdprKyEqIoIiwsDDKZDD/++CN27NghdVkAGKychiAIllGr7EtcZ0VERM6rT58+ePXVV3HPPfcgODgYGzZswOjRo6UuCwCnAp1KUpQS+3NLkH2Z66yIiMhx/XERemNTfG+88QbeeOONRq/v2rWr1TVr1qyxOh8QENBh04YcsXIiSXUL2E9wATsREZEkGKyciHkq8NTVCuiNJomrISIicj0MVk4kLsgbvgo36AwmnCuubPkCIiIisikGKycikwnoY9nPigvYiYiIOhuDlZOxrLPiAnYiIvoDe9jnyd6ZTDe3lMauvhWo1+uxb98+bN++HXv27EFubi6qqqoQHByMgQMHYtasWRg5cmST12dkZGDZsmU4cuQIqqqqEBcXh/HjxyMtLQ2+vr7tquns2bNYvHgxMjIyUFxcjNDQUAwfPhwLFixA9+7d2/tRO0xyVO06qxMcsSIiojru7u4QBMHyc0wQBKlLsjuiKEKn06G4uBgymQweHh7t6kcQ7Si+ZmRk4L777gNQu/X8bbfdBh8fH5w8eRLZ2dkAgCeffBIff/xxg/8o3n33XbzwwgsQBAFDhgxBeHg49u/fj6tXr6JXr144cOAAQkJC2lTPwYMHcf/990Oj0SApKQnJycnIzs7GiRMn4OPjg4yMDNx5551t6lOtVkOpVEKlUsHf379N17bGmasVeOC9ffDxkOP3hQ9AJuP/PEREVLup5sWLFzlq1QJvb29ERkY2CFat/fltVyNW5psqPvfccxgyZIjVuQ0bNuDxxx/Hp59+ikGDBmHq1KmWc8eOHcOcOXMgl8uxdetWPPTQQwAAjUaD0aNHY9euXXjqqaewcePGVtei0WgwYcIEaDQapKWlYcmSJZZz//jHP7B06VJMmDABZ86cgZeX101+ctuJD/WBwk2GKp0R+aVV6B7avpE6IiJyLr6+vujZsyf0er3UpdgtuVwONze3mxvREx3IjBkzRADivffea3X80UcfFQGIM2fObHBNfn6+KJPJRADiqVOnWv1eH374oQhATEhIEI1Go9U5o9EoJiQkiADEjz/+uE2fQaVSiQBElUrVpuvaYvQHB8S4V34Qtxy/1GHvQURE5Epa+/PboRavp6SkAAAKCwstx3Q6HbZt2wYAmDx5coNr4uLiMGjQIABAenp6q9/L3Paxxx6zuvEjUDuyNnHiRADA5s2b2/AJOkey+ZuBXMBORETUqRwqWOXm5gIAIiMjLcdycnKg0WgAAAMGDGj0OvPxY8eOtfq9zG1t2WdnMW8UygXsREREncuu1lg15+rVq5Z7/YwfP95yPC8vD0DtfX/8/PwavTY2NtaqbUsqKipQWloKAOjSpUuzfRYXF6Oqqgo+Pj6NttNqtdBqtZbXanXHh536Wy6IoshvfxAREXUShxixMhgM+Mtf/gKVSoW+ffti1qxZlnMVFRUA0GSwAWDZaqG1ocbcZ3P91t++obl+ly5dCqVSaXmYA1lHSgj3g5tMwHWNHpdVNR3+fkRERFTLIYLVU089hV27diE4OBgbN25s994SUkhLS4NKpbI86q8P6yie7nL0DK8dvcvmDZmJiIg6jd0Hq+eeew6rVq1CYGAgdu7ciYSEBKvz5um/qqqqJvuorKy9b15r942qP6XYVL/mPlvqV6FQwN/f3+rRGcwL2E8wWBEREXUauw5Wc+bMwfLlyxEQEIAdO3ZYvhVYX9euXQEA5eXlVlN49ZlHicxtW+Ln54egoCAAQEFBQbN9hoSENDsNKZUb66y4gJ2IiKiz2G2wevnll7Fs2TIolUrs2LGjyW/n9erVC97e3gCAzMzMRtuYj/fv37/V729ua8s+O5P5m4HccoGIiKjz2GWwmjt3Lt566y0olUrs3LkTt99+e5NtPTw8LPcP/Oqrrxqcv3DhAg4dOgQAGDt2bKtrMLf9+uuvG9yQ0WQyYcOGDQCAcePGtbrPztQ70h+CAFxTa1FcoW35AiIiIrppdhes5s2bhzfffBMBAQEthiqzuXPnQhAErF69Gtu3b7cc12g0mDFjBoxGI8aPH4/ExESr644cOYLExMQGxwEgNTUVUVFRyMnJwfz5863OzZ8/Hzk5OYiJibG6tY498VG4oVtI7RTlCY5aERERdQq7ugnzli1b8MgjjwCo3YAzKSmp0XYhISF4++23rY7Vvwnz0KFDERYWhv379+PKlStN3oR5z549GDZsGAA0elPK+jdhTk5OttyEOTs7225vwlzfs/8+hi2/XcZLD/TC/wzr0aHvRURE5Mwc8ibMZWVllueZmZlNrm+Ki4trEKyef/559O3bF++88w6OHDmCqqoqdOnSBWlpaUhLS2ty89DmDBo0CL/99hsWLVqEjIwMbNq0CaGhoZg6dSoWLFiA+Pj4NvfZmZKj/bHlt8vccoGIiKiT2NWIlSvozBGrQ2dLMPlfhxEb5IX9L9/Toe9FRETkzFr789vu1liR7fSp23KhsKwaKo1e4mqIiIicH4OVEwvw9kBMoBcA4MQVTgcSERF1NAYrJ5ccVbuf1YlL3CiUiIioozFYOTnzDuzcKJSIiKjjMVg5OfMO7Ly1DRERUcdjsHJySdG1I1bniiuh0RkkroaIiMi5MVg5uTA/T4T5KSCKwKkrHLUiIiLqSAxWLsC8zorTgURERB2LwcoFmNdZcQd2IiKijsVg5QKSoszBiiNWREREHYnBygUk1y1gz7lWAa3BKHE1REREzovBygVEB3hB6eUOg0lE7rVKqcshIiJyWgxWLkAQBMuoFddZERERdRwGKxdhvrUNd2AnIiLqOAxWLqIPt1wgIiLqcAxWLsK85cKpK2oYjCaJqyEiInJODFYuoluwD3w85KjRm3C+pErqcoiIiJwSg5WLkMkEy3QgF7ATERF1DAYrF2LeKJTrrIiIiDoGg5ULSeKIFRERUYdisHIh5gXsJy+rYTKJEldDRETkfBisXEiPMF94uMlQoTWgoEwjdTlEREROh8HKhbjLZUiM8APAdVZEREQdgcHKxSRxB3YiIqIOw2DlYnjPQCIioo7DYOVizCNWJy+rIYpcwE5ERGRLDFYuJjHCD3KZgNIqHa6qa6Quh4iIyKkwWLkYT3c5eob5AgCyL3EBOxERkS0xWLkgywJ2rrMiIiKyKbsLVmfOnMGKFSuQmpqKvn37ws3NDYIgYPHixU1eIwhCqx7r1q1rdR1r1qxpsb/t27fb4iN3OvMO7NxygYiIyLbcpC7gj1auXIn333+/TddMmzatyXMFBQXYvXs3BEHA0KFD21xPfHw8Bg8e3Oi56OjoNvdnD8w7sJ/glgtEREQ2ZXfBKjk5GS+++CJSUlLQv39/LFmyBF988UWz16xZs6bJc7Nnz8bu3bsxfPhwxMXFtbmewYMHN9u/I+pTN2J1RVWD0kotgn0VEldERETkHOwuWM2cOdPqtUzW/tnKmpoa/Pvf/wYAzJgx46bqcia+Cjd0C/FBXkkVTlxW466EUKlLIiIicgp2t8bKljZt2oTy8nIEBQVhzJgxUpdjV8zrrLgDOxERke3Y3YiVLX3++ecAgL/85S9QKNo33XX27FnMmzcPRUVF8PX1RXJyMkaPHo2QkBBbltrpkqOV+OG/V3CCWy4QERHZjNMGq/z8fOzevRvAzU0DHjx4EAcPHrQ65unpiYULF+KVV15p8XqtVgutVmt5rVbbR5BJ5j0DiYiIbM5ppwJXr14NURQxYMAA3HLLLW2+PiIiAq+++ioOHz6M4uJiqNVqHD16FFOnToVWq8XcuXOxZMmSFvtZunQplEql5REbG9uej2Nz5qnAC6UaqGv0EldDRETkHJwyWJlMJss3+Z544ol29fHggw9i8eLFGDhwIEJCQuDn54cBAwZg7dq1ePvttwEAb7zxBq5du9ZsP2lpaVCpVJZHYWFhu+qxtUAfD0QHeAGovW8gERER3TynDFYZGRkoKCiAl5cXJk+ebPP+n3vuOYSEhECr1WLHjh3NtlUoFPD397d62AvLAnbuwE5ERGQTThmszIvWx48fD6VSafP+5XI5evbsCQC4ePGizfvvLOaNQjliRUREZBtOF6zKysrw3XffAejYvatKS0sBAH5+fh32Hh2NWy4QERHZltMFq/Xr10Or1SI+Pr5dt7BpjaysLOTk5AAABg4c2CHv0RnMI1ZniypRrTNKXA0REZHjc7pgZZ4GfOKJJyAIQrNt09PTkZiYiHvvvdfquEajwYcffoiKiooG1+zbtw/jx48HUHu7G0cOVmF+CoT4KmASgVNXOR1IRER0s+xuH6usrCzMnj3b8vrcuXMAgE8++QQ//PCD5Xh6ejoiIyOtrj127BiOHz8OuVyO1NTUFt9LpVLhzJkzqKmpsTqu0+nw9NNPY86cOUhJSUGXLl1gMBiQk5OD7OxsAEDfvn3xzTfftPdj2gVBEJAU5Y+9OcU4cVmN/l0CpS6JiIjIodldsFKr1Th8+HCD4xcvXrRaKF5/000z82jVAw88gKioqHbX4O3tjfnz5yMzMxOnT5/GiRMnUF1djcDAQAwfPhyPPvooUlNT4eHh0e73sBfJ0XXBit8MJCIiummCKIqi1EW4ErVaDaVSCZVKZRdbL/y/36/gb+uzkBztjx+eGSJ1OURERHaptT+/nW6NFbWNeQH7masV0BlMEldDRETk2BisXFxMoBf8Pd2gN4rILWq4WJ+IiIhaj8HKxdUuYK8dtTpxid8MJCIiuhkMVoTkaG4USkREZAsMVnRjxIq3tiEiIropDFZkGbE6eVkNo4lfEiUiImovBitCtxBfeLnLUa03Iq+kUupyiIiIHBaDFUEuE9DHfENmLmAnIiJqNwYrAgAk1QWrE1zATkRE1G4MVgQASK5bwM4RKyIiovZjsCIAQFL0jREr3uWIiIiofRisCADQM8wPHnIZ1DUGXLxeLXU5REREDonBigAAHm4yJET4AgCyL3GdFRERUXswWJGFZZ0VF7ATERG1C4MVWSRFcwE7ERHRzWCwIov6Wy5wATsREVHbMViRRe8If8gEoKRSh6IKrdTlEBERORwGK7Lw8pCjRxgXsBMREbUXgxVZ4UahRERE7cdgRVb68NY2RERE7cZgRVaS674ZeOIyR6yIiIjaisGKrJhHrC6VV+N6lU7iaoiIiBwLgxVZ8fd0R1ywNwCOWhEREbUVgxU1wB3YiYiI2ofBihpIiq6dDuSWC0RERG3DYEUNmEesOBVIRETUNgxW1ID51jZ5JVWoqNFLXA0REZHjYLCiBoJ9FYhUegIATl2pkLgaIiIix8FgRY1KsuzAznVWRERErWV3werMmTNYsWIFUlNT0bdvX7i5uUEQBCxevLjJaxYuXAhBEJp9nD59ul31nD17FqmpqYiJiYFCoUBMTAxSU1Nx/vz59n5Eh5Acbd6BneusiIiIWstN6gL+aOXKlXj//ffbdW2/fv1w6623NnpOqVS2ub+DBw/i/vvvh0ajQVJSEgYPHozs7GysXbsWGzduREZGBu6888521WrvkiwL2DliRURE1Fp2F6ySk5Px4osvIiUlBf3798eSJUvwxRdftOraMWPGYOHChTapQ6PRYMKECdBoNEhLS8OSJUss5/7xj39g6dKlmDBhAs6cOQMvLy+bvKc9MY9Y5RZVokZvhKe7XOKKiIiI7J/dBauZM2davZbJpJmtXLNmDS5fvoyEhIQG05CLFy/Gpk2bkJOTg3Xr1mHWrFmS1NiRIvw9EezjgdIqHU5frcCtsQFSl0RERGT37G6Nlb1IT08HADz22GMNwp1MJsPEiRMBAJs3b+702jqDIAiW+wZyOpCIiKh17G7E6mZkZWVh7ty5KCsrg1KpREpKCh5++GH4+fm1ua9jx44BAAYMGNDoefNxcztnlBytxP7cEmRf4gJ2IiKi1nCqYLV161Zs3brV6phSqcTy5csxderUVvdTUVGB0tJSAECXLl0abRMbGwsAKC4uRlVVFXx8fNpZtf1K5gJ2IiKiNnGKqcD4+HgsWbIEx44dQ1lZGcrKynDgwAGMGjUKKpUK06ZNw/r161vdX0XFjU0xmwpMvr6+ludqddMjOlqtFmq12urhKMwL2E9fqYDeaJK4GiIiIvvnFMFqypQpSEtLw6233orAwEAEBgZi0KBB2Lp1K5555hkAwPPPPw+dTtfptS1duhRKpdLyMI90OYLYQG/4KdygM5pwtqhS6nKIiIjsnlMEq+YsXLgQcrkcxcXFOHz4cKuuqb8mq6qqqtE2lZU3goa/v3+TfaWlpUGlUlkehYWFraxcejLZjQXs3IGdiIioZU4frIKCghAWFgYAuHjxYquu8fPzQ1BQEACgoKCg0TbmgBQSEtLs+iqFQgF/f3+rhyNJjjavs3KcKUwiIiKpOH2wMhqNUKlqR1va8u3A/v37AwAyMzMbPW8+bm7nrJK45QIREVGrOX2w2rJlCzQaDQRBaHLrhMaMHTsWAPD111/DZLJeuG0ymbBhwwYAwLhx42xXrB2qP2JlMokSV0NERGTfHD5YFRQU4Msvv0RNTU2Dc999951lJ/fHH38cERERVuePHDmCxMREJCYmNrg2NTUVUVFRyMnJwfz5863OzZ8/Hzk5OYiJiWnTNg6OqHuIDzzdZdDojMgrbXy9GREREdUSRFG0q2GIrKwszJ492/L63LlzKCkpQUxMDKKjoy3H09PTERkZiePHjyMlJQW+vr5ISUlBdHQ0qqurcfLkSeTm5gIAhg0bhi1btlhtkQAAe/bswbBhwwAAjf021L8Jc3JyMpKTk5GdnY3s7Gz4+Pi06ybMarUaSqUSKpXKYdZbjf3oII4VlOP9x27FI7dGt3wBERGRk2ntz2+72yBUrVY3+u29ixcvWi0+12q1AGo36nzllVdw9OhRnD17FllZWdDpdAgJCcGoUaMwefJkTJw4sV33HBw0aBB+++03LFq0CBkZGdi0aRNCQ0MxdepULFiwAPHx8e3/oA4kKcofxwrKcfKymsGKiIioGXY3YuXsHHHE6usjBZi7+XcM6hGM9TPbNkJHRETkDFr789vh11hRxzMvYM++pG50ypSIiIhqMVhRi3qG+8JdLkBVrcel8mqpyyEiIrJbDFbUIoWbHD3DavcAy77EjUKJiIiawmBFrWK+ITM3CiUiImoagxW1yo11VgxWRERETWGwola5cWsbTgUSERE1hcGKWqV3pD8EASiq0KJI3XCXeyIiImKwolby9nBDfGjtzvUctSIiImocgxW1WnIUF7ATERE1h8GKWi0p6sZGoURERNQQgxW1WlLdlgvZHLEiIiJqFIMVtZp5xOri9WqUa3QSV0NERGR/GKyo1ZRe7ogN8gIAnOQCdiIiogYYrKhNks3rrDgdSERE1ACDFbXJjR3YOWJFRET0RwxW1CbmHdg5YkVERNQQgxW1iXkBe15JFaq0BomrISIisi8MVtQmoX4KhPsrIIrAqSucDiQiIqqPwYrazLKA/RKnA4mIiOpjsKI2S6pbwM57BhIREVljsKI2u7GAncGKiIioPgYrajPzlgu51ypQozdKXA0REZH9YLCiNotSeiLQ2x0Gk4icaxVSl0NERGQ3GKyozQRBsGy7wHVWRERENzBYUbskRdets+I3A4mIiCwYrKhdbtwzkCNWREREZgxW1C7mBeynr6hhMJokroaIiMg+MFhRu8QFecNX4QatwYRzxVVSl0NERGQXGKyoXWQyAX0iuc6KiIioPgYrajfLAvbLDFZERESAHQarM2fOYMWKFUhNTUXfvn3h5uYGQRCwePHiRtubTCYcOnQICxYswODBgxEcHAx3d3eEhITgvvvuw/r16yGKYpvrWLNmDQRBaPaxffv2m/24Do1bLhAREVlzk7qAP1q5ciXef//9Vrc/f/48Bg0aBAAICgrCgAEDEBgYiPPnzyMjIwMZGRn4+uuvsWnTJnh4eLS5nvj4eAwePLjRc9HR0W3uz5kk141YnbyshskkQiYTJK6IiIhIWnYXrJKTk/Hiiy8iJSUF/fv3x5IlS/DFF1802V4QBNxzzz146aWXcN9990Eul1vO7d27FyNHjsQPP/yA//t//y8WLFjQ5noGDx6MNWvWtOejOL0eob5QuMlQqTXgQpkG3UJ8pC6JiIhIUnYXrGbOnGn1WiZrfrYyPj4eu3btavTc0KFDMXfuXMyfPx/r1q1rV7CiprnJZUiM9MdvheXIvqRisCIiIpfX5jVWRUVF0Ol0rWpbXFyMffv2tbkoW0pJSQEAFBYWSlqHs0qKqp0O5DorIiKidgSryMhIbNy40fJapVKhT58+OHz4cIO2O3bswLBhw26uwpuUm5sLoLbu9jh79izmzZuHJ598Ei+88AI+//xzlJSU2LJEh5ZsWcDObwYSERG1eSrwj9+wMxgMOH36NKqq7G+TSI1Gg+XLlwMAxo8f364+Dh48iIMHD1od8/T0xMKFC/HKK6+0eL1Wq4VWq7W8Vquda2Qnud49A0VRhCBwATsREbkuu9tuwZZmz56NvLw8REVF4R//+Eebro2IiMCrr76Kw4cPo7i4GGq1GkePHsXUqVOh1Woxd+5cLFmypMV+li5dCqVSaXnExsa29+PYpYRwP7jJBFzX6HFFVSN1OURERJJy2mC1aNEirF27Fp6envjmm28QHBzcpusffPBBLF68GAMHDkRISAj8/PwwYMAArF27Fm+//TYA4I033sC1a9ea7SctLQ0qlcrycLa1Xp7ucvQI8wXAHdiJiIicMlgtW7YMCxYsgEKhQHp6umWfK1t57rnnEBISAq1Wix07djTbVqFQwN/f3+rhbMw3ZM7mAnYiInJx7dpuoaqqCmVlZQBg+bWiosLy3KyysvImy2u7FStWYM6cOfDw8MCmTZvw4IMP2vw95HI5evbsiZKSEly8eNHm/Tua5Ch/bPwPcIIjVkRE5OLaFayeeuopPPXUU1bHxo0b16BdZy9m/vDDD/Hss89aQtXIkSM77L1KS0sBAH5+fh32Ho4iKZq3tiEiIgLaEaxee+21jqjjpn388cd4+umnLaFq1KhRHfZeWVlZyMnJAQAMHDiww97HUfSO9IcgAFfVNSiu0CLUTyF1SURERJJwimD12WefYfbs2W0OVenp6UhLS0N0dLTV7u0ajQarV6/G1KlTG4xI7du3D9OmTQNQe7sbBivAV+GGbiE+OF9chROXVbi7V5jUJREREUnC7m5pk5WVhdmzZ1tenzt3DgDwySef4IcffrAcT09PR2RkJI4fP45Zs2ZBFEV0794dGzdutNrAtL4/3vNPpVLhzJkzqKmx3iZAp9Ph6aefxpw5c5CSkoIuXbrAYDAgJycH2dnZAIC+ffvim2++scVHdgrJUcq6YKVmsCIiIpfV5mB19epV5OTkoH///vD19bUc1+v1WLRoEdavX48rV64gMTERCxcuxOjRo9vUv1qtbnQX94sXL1otFDdvulleXm7ZtPT06dM4ffp0k3239mbK3t7emD9/PjIzM3H69GmcOHEC1dXVCAwMxPDhw/Hoo48iNTUVHh4ebfhkzi0pyh9bfrvMHdiJiMilCeIft1Jvwd///nf8+9//RmFhoVWwePbZZ/Hhhx9CqVQiPj4eJ0+ehE6nw65du3DXXXfZvHBHpVaroVQqoVKpnGrrhYNnS/D4vw6jS5A39r0s7W2MiIiIbK21P7/bvI/V3r178fDDD1uFquLiYnz00Ufo3bs3zp8/j6NHj+LkyZMIDQ3FO++8075PQA7FfDPmgjINVNV6iashIiKSRpuDVWFhIZKSkqyO/fDDDzCZTHjxxRcREBAAAIiLi8P06dMbndYj5xPg7YHoAC8AwEluu0BERC6qzcGqpqbGam0VAOzfvx+CIODee++1Oh4fH4/r16/fXIXkMMw3ZOY6KyIiclVtDlbdunXD8ePHrY7t3r0bcXFxDW4wXFlZiaCgoJsqkBxHclTdrW24AzsREbmoNgercePGYe3atdiwYQMKCwvxv//7v7hw4QImTJjQoO2vv/6K7t2726RQsn/J3IGdiIhcXJu3W3j55ZexdetWTJo0CYIgQBRF9OrVC6+++qpVu9LSUmzZsgUvvfSSzYol+2ZewH6uuBIanQHeHna3TRoREVGHavNPPh8fHxw5cgTp6ek4f/484uLiMGbMGHh6elq1u3TpEl5//XWMHz/eZsWSfQvz90SonwLFFVqculKB2+ICpS6JiIioU7VrSMHNzQ2PPvpos21uueUW3HLLLe0qihxXcpQ/dp8pxonLKgYrIiJyOW0OVm3dSV0QBHz//fdtfRtyUMnRytpgdYnrrIiIyPW0OVj98MMP8PT0REREBFqzabsgCO0qjByTeZ1VNrdcICIiF9TmYBUdHY1Lly4hJCQEkydPxmOPPYaIiIiOqI0cUFLdlgs51yqgNRihcJNLXBEREVHnadfO67t370ZKSgoWLVqE2NhYDB8+HKtXr0ZFRUVH1EgOJCbQC0ovd+iNInKvVUpdDhERUadqc7ACgKFDh+KTTz7B1atXsXHjRgQHB+Ppp59GWFgYxo0bh40bN0Kr1dq6VnIAgiBYpgO5AzsREbmadgUrM3d3dzzyyCPYsGEDrl27ZglbEydOxD//+U9b1UgOxrxRaDYXsBMRkYu5qWBlptVq8dNPP+H777/HsWPH4Onpia5du9qia3JAXMBORESuqt3BymQy4aeffkJqairCw8MxadIkVFdX47PPPkNRURGmTJliyzrJgZhHrE5dUcNoavmbo0RERM6izd8KPHToEL766it8++23KC0txZ133oklS5ZgwoQJCAkJ6YgaycF0C/aBt4ccGp0R54sr0TPcT+qSiIiIOkWbg9XgwYPh5eWFESNGYNKkSZYpv4KCAhQUFDR6Tf/+/W+qSHIsMpmAPpH+yLxwHdmXVQxWRETkMtp1S5vq6mps2rQJmzdvbradKIoQBAFGo7FdxZHjSo5W1garS2qMTZG6GiIios7R5mC1evXqjqiDnAy3XCAiIlfU5mA1bdq0jqiDnIx5B/YTl9QwmUTIZLy1EREROT+bbLdA9Ec9w33hIZehQmtA4XWN1OUQERF1CgYr6hDuchkSI2sXrZ+4zI1CiYjINTBYUYexbBR6ieusiIjINTBYUYcxr7PK5ogVERG5CAYr6jDmHdhPXFJBFLkDOxEROT8GK+owiRF+kMsElFbpcE2tlbocIiKiDsdgRR3G012OHqG+ALjOioiIXAODFXWopOi6BezcKJSIiFyA3QWrM2fOYMWKFUhNTUXfvn3h5uYGQRCwePHiFq/NyMjAiBEjEBISAi8vLyQmJuLVV19FZWVlu+s5e/YsUlNTERMTA4VCgZiYGKSmpuL8+fPt7tOVJJsXsF/iAnYiInJ+dhesVq5ciWeffRZr165FdnZ2q+8z+O677+K+++7D9u3bkZSUhIcffhgqlQpLlizBgAEDUFJS0uZaDh48iH79+mHt2rUICAjA2LFjERAQgLVr1+KWW27Br7/+2uY+XY15y4WTHLEiIiIXYHfBKjk5GS+++CLWr1+PU6dOYcqUKS1ec+zYMcyZMwdyuRzbtm3D3r178c033+DcuXO49957cebMGTz11FNtqkOj0WDChAnQaDRIS0tDdnY2vv76a2RnZyMtLQ1VVVWYMGECqqur2/tRXUKfumB1WVWD0kouYCciIudmd8Fq5syZeOuttzB58mQkJiZCJmu5xKVLl0IURUyfPh0PPfSQ5bi3tzdWrVoFmUyGTZs24fTp062uY82aNbh8+TISEhIaTEMuXrwYCQkJKCwsxLp161r/4VyQn6c7uoX4AOAO7ERE5PzsLli1lU6nw7Zt2wAAkydPbnA+Li4OgwYNAgCkp6e3ul9z28cee6xBuJPJZJg4cSIAYPPmze2q25WYpwMZrIiIyNk5fLDKycmBRlN7k98BAwY02sZ8/NixY63u19zWln26qhs7sHOdFREROTc3qQu4WXl5eQCAgIAA+Pn5NdomNjbWqm1LKioqUFpaCgDo0qVLs30WFxejqqoKPj4+jbbTarXQam+sLVKrXW/UJrluy4UT3MuKiIicnMOPWFVUVABAk8EGAHx9azepbG2oMffZXL/mPlvqd+nSpVAqlZaHOZC5EvOIVX6pBuoavcTVEBERdRyHD1b2Li0tDSqVyvIoLCyUuqROF+TjgegALwDAKa6zIiIiJ+bwwco8/VdVVdVkG/MGof7+/m3qs7l+62862ly/CoUC/v7+Vg9XZN52IZvBioiInJjDB6uuXbsCAMrLy62m8OozjxKZ27bEz88PQUFBAICCgoJm+wwJCWl2GpJqmXdg5zorIiJyZg4frHr16gVvb28AQGZmZqNtzMf79+/f6n7NbW3ZpyuzLGDniBURETkxhw9WHh4eGDlyJADgq6++anD+woULOHToEABg7Nixre7X3Pbrr7+GyWSyOmcymbBhwwYAwLhx49pVt6sxL2DPLapAta51tykiIiJyNA4frABg7ty5EAQBq1evxvbt2y3HNRoNZsyYAaPRiPHjxyMxMdHquiNHjiAxMbHBcQBITU1FVFQUcnJyMH/+fKtz8+fPR05ODmJiYjB16tSO+VBOJtxfgRBfD5hE4PRVjloREZFzEkRRFKUuor6srCzMnj3b8vrcuXMoKSlBTEwMoqOjLcfT09MRGRlpef3uu+/ihRdegCAIGDp0KMLCwrB//35cuXIFvXr1woEDBxASEmL1Xnv27MGwYcMAAI39Nhw8eBD3338/NBoNkpOTkZycjOzsbGRnZ8PHxwcZGRm488472/T51Go1lEolVCqVyy1kn/b5EezNKcaiMcmYcmec1OUQERG1Wmt/ftvdBqFqtRqHDx9ucPzixYu4ePGi5XX9TTcB4Pnnn0ffvn3xzjvv4MiRI6iqqkKXLl2QlpaGtLS0JjcPbc6gQYPw22+/YdGiRcjIyMCmTZsQGhqKqVOnYsGCBYiPj2/7B3RhydH+2JtTjJPcgZ2IiJyU3Y1YOTtXHrH68fcrmL0+C32jldj6zGCpyyEiImq11v78doo1VuQYzFsunLlaAZ3B1EJrIiIix8NgRZ0mNsgLfp5u0BlNyC1qfM8xIiIiR8ZgRZ1GEAQkRXE/KyIicl4MVtSpuAM7ERE5MwYr6lTJ0bXBivcMJCIiZ8RgRZ3KfGubU1fUMJr4hVQiInIuDFbUqbqF+MLLXQ6Nzoi8kiqpyyEiIrIpBivqVHKZgN6RtZu1nuBGoURE5GQYrKjTWdZZcQE7ERE5GQYr6nSWbwZyATsRETkZBivqdH3q9rLKvqRq9ObXREREjorBijpdQrgf3OUC1DUGXLxeLXU5RERENsNgRZ3Ow02GXhFcwE5ERM6HwYokkRRpXsDOdVZEROQ8GKxIEuaNQrM5YkVERE6EwYokkRTNESsiInI+DFYkid4R/pAJQEmlFkXqGqnLISIisgkGK5KEl4cc8aG+ADgdSEREzoPBiiSTzOlAIiJyMgxWJJmkuo1CueUCERE5CwYrkkxSFEesiIjIuTBYkWTMt7a5VF6N61U6iashIiK6eQxWJBmllzvigr0B8IbMRETkHBisSFLJddOBXGdFRETOgMGKJGWeDszmiBURETkBBiuSlHnLhROXOGJFRESOj8GKJGXecuF8SRUqtQaJqyEiIro5DFYkqRBfBSKVngCAU1c4HUhERI6NwYokZx61yuZ0IBEROTinCVb5+fkQBKFVj3379rWqz4ULF7bY1+nTpzv4kzk/bhRKRETOwk3qAmzF19cX06ZNa/L8yZMncfToUfj5+eG2225rU9/9+vXDrbfe2ug5pVLZpr6oIcsCdm65QEREDs5pglVISAjWrFnT5PkRI0YAAB577DH4+Pi0qe8xY8Zg4cKFN1EdNcc8FZhbVIkavRGe7nKJKyIiImofp5kKbM6lS5fw008/AQBmzJghcTX0R5FKTwT5eMBoEnHmaoXU5RAREbWbSwSrNWvWwGQyISkpCXfccYfU5dAfCIJwYwE7pwOJiMiBOc1UYHPMU4TtHa3KysrC3LlzUVZWBqVSiZSUFDz88MPw8/OzYZWuLTlaif25JbxnIBEROTSnD1Z79+7F2bNn4eHhgSlTprSrj61bt2Lr1q1Wx5RKJZYvX46pU6c2e61Wq4VWq7W8VqsZHBpjHrHiDuxEROTInH4q8PPPPwcAjB49GiEhIW26Nj4+HkuWLMGxY8dQVlaGsrIyHDhwAKNGjYJKpcK0adOwfv36ZvtYunQplEql5REbG9vuz+LMzDdjPnW1AnqjSeJqiIiI2kcQRVGUuoiOolarERkZCY1Ggx9//BEPPfSQzfp+9tlnsWLFCoSGhuLixYvw8PBotF1jI1axsbFQqVTw9/e3WT2OzmQS0e/1HajQGrD970OQGMHfGyIish9qtRpKpbLFn99OPWL19ddfQ6PRICYmBg888IBN+164cCHkcjmKi4tx+PDhJtspFAr4+/tbPaghmUxAb8sO7JwuJSIix+TUwco8DZiamgqZzLYfNSgoCGFhYQCAixcv2rRvV5Vs2YGd66yIiMgxOW2wOnnyJA4fPgxBEDB9+nSb9280GqFS1QYAfjvQNpKj6xawc8sFIiJyUE4brFatWgUAGDZsGLp3727z/rds2QKNRgNBEDBgwACb9++KzLe2OXlZDZPJaZf+ERGRE3PKYKXX6/Hll18CaHnvqg8++ACJiYkNtk0oKCjAl19+iZqamgbXfPfdd5g5cyYA4PHHH0dERISNKndt3UN8oHCToUpnRH5pldTlEBERtZlT7mP1ww8/oKioCAEBARg3blyzbUtKSnDmzJkG4aisrAxTpkzB3/72N6SkpCA6OhrV1dU4efIkcnNzAdSOhq1cubLDPoercZPL0DvSH8cLy5F9WY3uob5Sl0RERNQmThmszIvWJ0+eDE9Pz3b1ERsbi1deeQVHjx7F2bNnkZWVBZ1Oh5CQEIwaNQqTJ0/GxIkTbb4o3tUlR9cGqy9/uYBB8cEI9lVIXRIREVGrOfU+VvaotftguKpjBdfx2Ke/QmswIcLfE8snpWBgtyCpyyIiIhfHfazIIaV0CcR3/zMI3UN9cFVdg0mf/YoPd5/lYnYiInIIDFZkd3pH+mPr04MxNiUaRpOIt346g2mrj6CkUtvyxURERBJisCK75KNww7IJ/fDP8bfA012G/bklGPH+fvx6vlTq0oiIiJrEYEV2SxAETLg9Ft//z2D0CPNFUYUWkz/7FSt25cLIqUEiIrJDDFZk93pF+GHL04Mwvn8MTCLwzs4cTPv8CIorODVIRET2hcGKHIK3hxvemdAPb/35Fni5y3HgbAlGLN+PQ2dLpC6NiIjIgsGKHMqjA2Kx5elB6Bnmi+IKLR5fdRjvZeRwapCIiOwCgxU5nJ7hftjy9GBMGBADUQTey8jFlFWHUVTR8PZDREREnYnBihySl4cc//xzPyyb0A/eHnIcOleKEe/vx4FcTg0SEZF0GKzIoY3rH4MtTw9Gr3A/lFTqMOXzw1i24wynBomISBIMVuTweoT54vunB2HSwFiIIrD857OY/NmvuKbm1CAREXUuBityCp7uciwddwvef+xW+HjIcTivDCPe3499OcVSl0ZERC6EwYqcyiO3RmPrM4PRO9IfpVU6TFt9BG//dAYGo0nq0oiIyAUwWJHT6R7qi/TZf8LkO7pAFIEPdp/F5M8O46qKU4NERNSxGKzIKXm6y7FkbF8sn5QCX4UbjuSXYcTy/dhzpkjq0oiIyIkxWJFTG90vClufGYykKH+UVemQuvoo3tx+mlODRETUIRisyOl1C/HBpr/9CVPujAMArNxzDo99+isul1dLXBkRETkbBityCZ7uciwak4wPJ/eHn8INmReuY8Ty/fj59DWpSyMiIifCYEUuZeQtkfjh2cFIjvZHuUaPJ9ZkYumPp6Dn1CAREdkAgxW5nLjg2qnB1D91BQB8su88Jn7yCy5xapCIiG4SgxW5JIWbHAtHJ+Hjv/SHn6cbsgrKMeL9/cg4yalBIiJqPwYrcmkPJkdi2zND0C9GCVW1HjPXZWLxDyehM3BqkIiI2o7Bilxel2BvfPvUn/DEoG4AgH8dyMOET35BYZlG4sqIiMjRMFgRAfBwk2HBw33wyZTb4O/phuOF5Ri5fD92nLgqdWlERORAGKyI6nkgKQLbnh2CW2MDoK4x4Mkv/oPXt57g1CAREbUKgxXRH8QGeeObWf8Hfx1SOzW4+mA+Hv34EKcGiYioRQxWRI3wcJPh1ZF98K+pA6D0csdvF1UYsXw/tmdfkbo0IiKyYwxWRM0Y3iccPz43BCldAlBRY8BTX2bhte+zoTUYpS6NiIjsEIMVUQuiA7zwzaz/g1l3dQcArP3lAv688hdcKK2SuDIiIrI3ThOsUlNTIQhCs4+ampo29/uf//wHjz76KMLDw+Hp6Ylu3brhmWeeQVFRUQd8CrJX7nIZ0kb0xuepAxDg7Y7fL6kwavkBbPsvpwaJiOgGN6kLsLVBgwahR48ejZ6Ty+Vt6mvjxo2YNGkSDAYDbr/9dnTr1g2ZmZn44IMP8O233+LAgQNNvhc5p3sSw/Hjs0Pw7L+PIfPCdfzPV1n49XwcXh3ZG57ubfvvi4iInI/TBauZM2ciNTX1pvu5fPkypk2bBoPBgE8++QRPPvkkAMBoNCI1NRVffvklJk+ejMOHD0MQhJt+P3IcUQFe+PeTd2LZzhys3HMOX/x6AVkF1/HB5P7oFuIjdXlERCQhp5kKtLX33nsPGo0Gw4cPt4QqoHbUa+XKlVAqlTh69Ch27NghYZUkFXe5DK88mIg1029HkI8HTlxW4+EVB7D1t8tSl0ZERBJisGpCeno6AGDy5MkNzvn6+mL06NEAgM2bN3dqXWRf7u4Vhh+fHYKBXYNQqTXgmX8fwz/Sf0eNnt8aJCJyRU43Fbh79278/vvvqKioQHBwMAYOHIgRI0ZAoVC0uo+KigqcPXsWADBgwIBG2wwYMABffPEFjh07ZpO6yXFFKD3x1V/vwHsZufhwz1l8dbgAxwrK8eHkFHQP9ZW6PCIi6kROF6zWrVvX4FhkZCQ+//xzPPjgg63qIz8/3/K8S5cujbaJjY0FAOTl5TXbl1arhVartbxWq9WtqoEci5tchhcf6IWB3YLw/IbjOHWldmpw2p+6YnifcPSLCYBcxrV4RETOzmmmAvv164f3338f2dnZUKvVuHbtGnbs2IE//elPuHLlCkaPHo09e/a0qq+KigrLcx+fxhcj+/rWjkS0FJSWLl0KpVJpeZgDGTmnuxJC8eNzQ3BHtyBU6Yz4aM85jPvoEAb+bwZe/PY3/L/fr6BSa5C6TCIi6iCCKIqi1EV0JFEUMXbsWHz//ffo168fjh8/3uI1hw4dwqBBgwAAer0ebm4NB/Z27tyJ+++/Hx4eHlYjUn/U2IhVbGwsVCoV/P392/6ByCEYTSJ++O9l7Dh5DfvOFKOiXphylwu4s3sw7k0Mw729wxEb5C1hpURE1BpqtRpKpbLFn99OH6wA4LfffsOtt94KACgoKGhx1Oj333/HLbfcAgAoLy+HUqls0CY9PR3jxo1DSEgIiouLW11La/9gyHnojSYczSvDrtNF2HXqGvJLrW/mnBDui3sSwzG8dxhSugRyypCIyA619ue3062xakzv3r0tzy9evNhisIqLi7M8LygoQN++fRu0KSwsBAB07drVNkWS03KXy/CnHiH4U48QzBvZG+dLqrDr1DXsOlWEzAvXkXOtEjnXKvHx3nMI9HbHsF5huKd3GO5KCIW/p7vU5RMRURu4RLAqLS21PPfz82uxvb+/P3r06IGzZ88iMzOz0WCVmZkJAOjfv7/tCiWnJwgC4kN9ER/qiyfvike5Roe9OcXYdaoIe84U4bpGj83HLmHzsUtwkwkY2C0I9/YOx72JYejKzUeJiOyeS0wFvvvuu3jhhRfg7++PkpISuLu3PArw8ssv46233sLw4cOxc+dOq3OVlZWIjY1FeXk5tm/fjgceeKDVtXAqkJpiMJqQeeE6fj5dhIxT13C+2Pomz/GhPpaQdVtcINzkTvPdEyIiu+dSa6yOHz+OgoICjBgxwmqhuclkwurVq/H000+jpqYG8+bNw6JFiyzn09PTkZaWhujoaOzatcuqz8uXL6Nnz57QaDT49NNP8de//hVA7S1tpk+fji+++AK33357m29pw2BFrZVXN2X48+kiHMkrg8F0439VpZc77u4VinsSw3B3QhiU3pwyJCLqSC4VrL777juMHTsWgYGB6N+/P8LDw1FeXo7s7GwUFBQAACZNmoR169ZZBa81a9Zg+vTpiIuLs9q7yuzbb7/FpEmTYDQacccdd6Br1644evQozp8/j/Dw8HbdhJnBitpDVa3H/tzaKcPdZ4pQrtFbzsllAgbEBWJ473Dc0zsM8dyUlIjI5lwqWOXl5WH58uXIzMxEXl4eSktLIYoiwsPDMXDgQEyfPh0jRoxocF1LwQoA/vOf/2DJkiXYv38/VCoVIiMjMWrUKMyfPx/h4eFtrpXBim6W0SQiq+A6dp2q/ZZhblGl1fluIT64JzEM9/YOw+1dg+DOKUMiopvmUsHKkTBYka0VlGqw63TtlOGv50uhN974X9rP0w1DE0Jxb+/aKcNAHw8JKyUiclwMVnaKwYo6UkWNHgdyS5BRN2VYVqWznJMJwG1xgZYF8D3CfNu0PpCIyJUxWNkpBivqLEaTiOOF5fj5dO2eWaevVlid7xLkjXsSwzC8dzgGdguChxunDImImsJgZacYrEgqhWUa7D5ThF2nivDLuVLojCbLOV+FG+5KCME9ieEY1isUwb4KCSslIrI/DFZ2isGK7EGV1oADZ0vqtnMoRknljftZCgKQEhuAe3uHY3jvcCSEc8qQiIjByk4xWJG9MZlE/PeSCj+fuoaMU0U4eUVtdT46wAsDugYiIdwPPcN8kRDuh9ggb97TkIhcCoOVnWKwInt3ubwaP58uws+ni3DwbAm0BlODNgo3GXqE+aJnmC96hvshIdwPCeG+iA30hoyBi4icEIOVnWKwIkei0Rlw+HwZTl5R42xRJXKuVeBsUWWjYQsAPN1rA1dCmF9d4Kod4YoO8GLgIiKHxmBlpxisyNEZTSIKyzTIuVaB3LqwlXOtEueKK6FrInB5uctrR7jqglZCuC96hjFwEZHjYLCyUwxW5KwMRhMKyjTIuVaJ3Hqh63xxldU3EOvz9pBbphPN67d6hvsiOsCLC+aJyK4wWNkpBityNQajCRfKNMitG9nKuVaB3GuVOF9SabVLfH0+HnL0CPdDQr2wlRDuh0ilJwMXEUmCwcpOMVgR1dIbTbhQWlU3wlWJnKIK5NaNcBlMjf+15Ktwq13DFW4OXLXTihH+DFxE1LEYrOwUgxVR8/RGE/JLqm6MbhXVjnTllzQduPw83SxTiT3CzOu4/BDur2DgIiKbYLCyUwxWRO2jM5iQV1JlCVq1U4sVyC/VwNhE4PL3dLOMavUM80PXEG9E+HshKsATSi93hi4iajUGKzvFYEVkW1qDEXklVVZhK/daJfJLq9BE3gJQuzVEpNILkUpPRCg9EaX0qv01wBMR/rXHA7wZvoioVmt/frt1Yk1ERDancJMjMcIfiRHWf9FpDUacL66yBK2caxW4VF6NK6oalFXpUKOvHQHLK6lqsu+mwlek0tNynOGLiOpjsCIip6Rwk6N3pD96Rzb8l2WN3oirqhpcUdXgqroal8tr6l7XBq+bCV/1QxfDF5HrYbAiIpfj6S5H1xAfdA3xabJNjd6Ia+qa2tBlFb5qA9hVVQ1K2xi+Ivw9ERnA8EXkzBisiIga4ekuR1ywD+KCWw5fV+qPdpXbPnyZpyEZvojsH4MVEVE7tTd8XVXdGAm7Ut728BXqq0CQjweCfD0Q5O2BIB8PBPt6IPAPzz3d5R3xsYmoGQxWREQdqK3h66qqBpfrRrvM4euqqgYlla0LX/X5eMitwleQjwJBPu4I8lEg2McDgT51Qazuub+nG0fEiG4SgxURkcRaG76K1FpcVlWjpFKLsiodSit1uK7RobRKh7J6z69X6WAwiajSGVFVVo3CsupW1eEuFyyjXkF/CF3BdcEs0McdwT61I2aB3u5wk8ts9dtA5BQYrIiIHICnuxxdgr3RJdi7xbaiKEJdY0BZlQ5lVVqUVelRVqW1hK7SKh3K/vBcozNCbxRRVKFFUYW21XUpvdwbHf0Krntd/3mQjwe8Pfhjh5wb/wsnInIygiBA6eUOpZc7ujXzzcf6avTGuiB242EdxLS4XqVHaVXtaFl5tR6iCKiq9VBV64FWTk96ussQXDfyFejtAX9Pd/h7udX96g5/T7e6X62P+3m6wctdzqlKsnsMVkREBE93OaICvBAV4NWq9kaTiHJNc0Gsbmqy8sZ5ndGEGr0Jl8qrcam8ddOT9bnJhGbDl/m4n2f9YzfaeHswmFHHY7AiIqI2k8sEBPsqEOyraFV7Uaxd81VWqUOZpnYErFyjh7paD3WNAepqPSpqDFDX6Gsf1XXP684bTSIMJtES0tpbc2OhzDqI1T9vHdx8GMyoFRisiIiowwmCAF+FG3wVbq1aJ1afKIrQ6IyWwFXRRPiq/dX6eEWNAapqPQwmEUaTiOsaPa5r9O36DDIB8Ks/Slb33M+zNnT5KNxqH3XPfc2vFXXnPG68VrhxKwxnxWBFRER2TRAES2iJVLb9elEUUaM31QthjYSyRo5V1LVVVeuhN4ow1V9ThrZPZdbnLhfg7WEOX3Kr5zcCmHVI81bUe+4hvxHcPNzg6S7jaJqdYLAiIiKnJggCvDzk8PKQI9zfs83Xi6IIrcH0hxBmPYVZpTWgSlf3q9ZoeV6pNUJjeW5Ajd4EANAbxXoh7ebJZYIlbNUPXbWBrf5oWr0RNEXtOXOo8/aofe7lXvt75S4XGNbagcGKiIioGYIgwNNdDk93OcIa3tO7TQxGEzR6Y10AqwthdaFLozOi0nxcd6PNH8/98TlQ+2WCihoDKmoMNvjEteQywRKyvNzlVs+9PeTwrPfcql0Tv5pDm6eHzPJcLnO+4OYUwUqv12Pfvn3Yvn079uzZg9zcXFRVVSE4OBgDBw7ErFmzMHLkyDb1uXDhQrz++uvNtjl16hQSExNvpnQiInIhbnIZ/OUy+Hu626Q/k0lsENRuhLMbwa2pETSrkKY1QqM3wmgSAdSGtcq6dh3Fw01mCW3eHrXh1cvjxnNzaPP8Y4Dz+MM15uDmIYOXhxuCvD3g5SHNOjanCFZ79+7FfffdBwCIiIjA4MGD4ePjg5MnT2Lr1q3YunUrnnzySXz88cdtHtbs168fbr311kbPKZXtmOwnIiKyEZnsxpcCbEVvNEGjM6JGb4RGZ0S1zohq/Y1fNToDaupea/RG1FiOW7dr8le9EWJtdoPOYILOYLLZlKjZG48kYer/6WrTPlvLKYKVTCbD+PHj8dxzz2HIkCFW5zZs2IDHH38cn376KQYNGoSpU6e2qe8xY8Zg4cKFNqyWiIjIfrnLZVB6yaD0ss2o2h+Z16yZg1m1zjp0VesMdb+aLCHOHNqaCnv1r9fojPCS8AbkThGs7rnnHtxzzz2Nnps4cSJ27tyJVatWYd26dW0OVkRERGQ79desBXbQe4jmITEJuMTdM1NSUgAAhYWFEldCREREHU3KbzM6xYhVS3JzcwEAkZGRbb42KysLc+fORVlZGZRKJVJSUvDwww/Dz8/P1mUSERGRg3P6YHX16lWsWbMGADB+/Pg2X29e/F6fUqnE8uXLWzWtqNVqodXeuFO8Wq1ucw1ERETkGJx6KtBgMOAvf/kLVCoV+vbti1mzZrX62vj4eCxZsgTHjh1DWVkZysrKcODAAYwaNQoqlQrTpk3D+vXrW+xn6dKlUCqVlkdsbOzNfCQiIiKyY4Io5QqvDjZz5kysWrUKwcHBOHToEBISEmzS77PPPosVK1YgNDQUFy9ehIeHR5NtGxuxio2NhUqlgr//Te40R0RERJ1CrVZDqVS2+PPbaUesnnvuOaxatQqBgYHYuXOnzUIVULt5qFwuR3FxMQ4fPtxsW4VCAX9/f6sHEREROSenDFZz5szB8uXLERAQgB07dli+FWgrQUFBCAsLAwBcvHjRpn0TERGR43K6YPXyyy9j2bJlUCqV2LFjBwYMGGDz9zAajVCpVADAbwcSERGRhVMFq7lz5+Ktt96CUqnEzp07cfvtt3fI+2zZsgUajQaCIHRIcCMiIiLH5DTBat68eXjzzTcREBDQ6lD1wQcfIDExscG2CQUFBfjyyy9RU1PT4JrvvvsOM2fOBAA8/vjjiIiIsM0HICIiIofnFPtYbdmyBf/7v/8LAOjRowc+/PDDRtuFhITg7bfftrwuKSnBmTNnGoSjsrIyTJkyBX/729+QkpKC6OhoVFdX4+TJk5bNRocNG4aVK1d20CciIiIiR+QUwaqsrMzyPDMzE5mZmY22i4uLswpWTYmNjcUrr7yCo0eP4uzZs8jKyoJOp0NISAhGjRqFyZMnY+LEiZDJnGbAj4iIiGzAqfexsket3QeDiIiI7IfL72NFRERE1NmcYirQkZgHCHnPQCIiIsdh/rnd0kQfg1Unq6ioAADeM5CIiMgBVVRUQKlUNnmea6w6mclkwuXLl+Hn5wdBEKQuxy6Z76dYWFjIdWh2gH8e9oV/HvaFfx72pSP/PERRREVFBaKiopr98hpHrDqZTCZDTEyM1GU4BN5b0b7wz8O+8M/DvvDPw7501J9HcyNVZly8TkRERGQjDFZERERENsJgRXZHoVDgtddeg0KhkLoUAv887A3/POwL/zzsiz38eXDxOhEREZGNcMSKiIiIyEYYrIiIiIhshMGKiIiIyEYYrEhSer0eu3btwksvvYTbb78dAQEBcHd3R0REBEaPHo1t27ZJXSIBePnllyEIAgRBwOLFi6UuxyXpdDosX74cgwcPRlBQEDw9PRETE4OHHnoIGzZskLo8l1NQUICnn34avXr1gpeXFzw9PdGtWzdMmzYNv/32m9TlOZ0zZ85gxYoVSE1NRd++feHm5tbqv48yMjIwYsQIhISEwMvLC4mJiXj11VdRWVnZMcWKRBLauXOnCEAEIEZERIgjR44UJ0yYICYnJ1uOP/nkk6LJZJK6VJd18OBBUSaTiYIgiADERYsWSV2SyyksLBT79OkjAhBDQkLEUaNGiRMnThT/9Kc/id7e3uL48eOlLtGl/Prrr6Kfn58IQIyOjhZHjx4tjh07VuzWrZsIQHRzcxO/+eYbqct0Ks8995zlZ0L9R0t/Hy1btkwEIAqCIN51113io48+KkZERIgAxF69eonFxcU2r5XBiiS1a9cucfz48eK+ffsanPv6669FuVwuAhDXrl0rQXVUVVUl9uzZU4yOjhbHjBnDYCUBjUYjJiYmigDEhQsXijqdzup8VVWVeOzYMWmKc1G33HKL5R999f88jEajOG/ePBGAGBAQIFZXV0tYpXP57LPPxBdffFFcv369eOrUKXHKlCkt/n2UlZUlCoIgyuVy8ccff7Qcr6qqEu+9914RQIf8o4TBiuzajBkzRADivffeK3UpLunZZ58VAYjbtm0Tp02bxmAlgfnz51t+iJP0SkpKLKMlRUVFDc4bDAbRy8tLBCBmZWVJUKFraM3fR48++qgIQJw5c2aDc/n5+aJMJhMBiKdOnbJpbVxjRXYtJSUFAFBYWChxJa5nz549WLFiBaZOnYoRI0ZIXY5L0uv1WLlyJQDgpZdekrgaAtCmjSdDQkI6sBJqjk6ns6zRnTx5coPzcXFxGDRoEAAgPT3dpu/NYEV2LTc3FwAQGRkpcSWupbKyEk888QTCw8Px3nvvSV2Oy8rKykJJSQmioqLQo0cP/P7773j99dcxa9YszJ07F9u2bYPJZJK6TJfi6+uLIUOGAADmzZsHvV5vOWcymbBw4UJUV1fjoYceQmxsrFRlurycnBxoNBoAwIABAxptYz5+7Ngxm763m017I7Khq1evYs2aNQCA8ePHS1uMi3nxxReRl5eH9PR0BAYGSl2Oy/rvf/8LAIiJicHcuXPxz3/+E2K9m2W8+eabSElJwXfffYcuXbpIVabL+eyzzzBixAh8+umn2LZtGwYMGAC5XI5jx47h0qVLmDJlCj744AOpy3RpeXl5AICAgAD4+fk12sYcfM1tbYUjVmSXDAYD/vKXv0ClUqFv376YNWuW1CW5jB07duCTTz7BY489hjFjxkhdjksrLS0FUPsv6jfffBOzZ8/GmTNnoFKpsHPnTiQkJODYsWMYOXKk1cgJdaxevXrhl19+wf33349Lly7h+++/x+bNm5GXl4cePXrg7rvvhr+/v9RlurSKigoAgI+PT5NtfH19AQBqtdqm781gRXbpqaeewq5duxAcHIyNGzfCw8ND6pJcgkqlwowZMxAaGooVK1ZIXY7LM49O6fV6TJo0CR988AESEhLg7++P4cOHY+fOnfD09ER2dja+/vpriat1HQcPHkTfvn2RnZ2Nr776ClevXkVZWRm2bt0KvV6PGTNmYMaMGVKXSRJhsCK789xzz2HVqlUIDAy0/KucOsff//53XLx4ER988AEX3tqB+lMYjY3adunSBSNHjgRQuwkidbzy8nKMHTsWxcXF2Lx5MyZNmoTw8HAEBgZi1KhR2L59O7y9vfH5559j9+7dUpfrssz/71RVVTXZxrxBqK1HF7nGiuzKnDlzsHz5cgQEBGDHjh2WbwVS50hPT4ebmxs++ugjfPTRR1bnTp8+DQBYtWoVMjIyEBERwVGSDta9e/dGnzfW5sqVK51Sk6vbtm0biouLER8fjzvuuKPB+e7du+OOO+7A7t27kZGRgWHDhklQJXXt2hVAbRCuqKhodJ2V+dvm5ra2wmBFduPll1/GsmXLoFQqsWPHjia/yUEdy2AwYO/evU2ez8/PR35+PuLi4jqxKtfUv39/CIIAURRRUlLS6LfMSkpKANxYL0Idq6CgAEDzoxxKpRIAUFZW1ik1UUO9evWCt7c3NBoNMjMzGw24mZmZAGr/P7MlTgWSXZg7dy7eeustKJVK7Ny5E7fffrvUJbmk8vJyiLUbBzd4TJs2DQCwaNEiiKKI/Px8aYt1ARERERg8eDCAxqf69Hq9JQQPHDiwU2tzVdHR0QBqR3BVKlWD83q9HllZWQCAbt26dWptdIOHh4dlmvyrr75qcP7ChQs4dOgQAGDs2LE2fW8GK5LcvHnz8OabbyIgIIChiugPXnvtNQDA0qVL8euvv1qOGwwGzJkzB+fPn4efnx+mT58uVYku5aGHHoKPjw+qq6vx17/+1epGvjqdDs8//zwKCgrg7u6OP//5zxJWSnPnzoUgCFi9ejW2b99uOa7RaDBjxgwYjUaMHz8eiYmJNn1fQay/KQpRJ9uyZQseeeQRALWbtSUlJTXaLiQkBG+//XZnlkZ/kJqairVr12LRokWYN2+e1OW4lMWLF2P+/Plwc3PDwIEDERERgaysLOTn58PLywvffvut5V/n1PG+/PJLTJ8+HQaDAaGhobj99tvh7u6OzMxMXLp0CTKZDB9++CGeeuopqUt1GllZWZg9e7bl9blz51BSUoKYmBjLKCJQu060/obS7777Ll544QUIgoChQ4ciLCwM+/fvx5UrV9CrVy8cOHDA9l/UsekNcojaaPXq1Y3esfyPj7i4OKlLdXm8V6C0fvrpJ/Ghhx4Sg4KCRHd3dzE2NlZMTU21+X3OqHWOHz8upqamit27dxcVCoXo4eEhxsXFiY8//rh4+PBhqctzOrt3727Vz4q8vLwG1+7cuVN88MEHxaCgIFGhUIg9e/YU09LSRLVa3SG1csSKiIiIyEa4xoqIiIjIRhisiIiIiGyEwYqIiIjIRhisiIiIiGyEwYqIiIjIRhisiIiIiGyEwYqIiIjIRhisiIiIiGyEwYqIiIjIRhisiMghrVmzBoIgID8/X+pSWmXhwoUQBEHqMoiogzFYEZFT+Oijj7BmzRpJa9BoNFi4cCH27NkjaR1EJB3eK5CIHJLRaIRer4dCoYAgCEhOTkZISIikoaakpAShoaF47bXXsHDhQqtzBoMBBoMBnp6e0hRHRJ3CTeoCiIjaQy6XQy6Xd+h7GAwGmEwmeHh43HRfbm5ucHPjX7lEzo5TgUTkkOqvseratStOnDiBvXv3QhAECIKAu+++29K2vLwcf//73xEbGwuFQoEePXrgzTffhMlksrTJz8+HIAh4++238d577yE+Ph4KhQInT56ETqfDggULcNttt0GpVMLHxwdDhgzB7t27ra4PDQ0FALz++uuWOswjV42tsTIYDFi0aJHlvbp27Yp//OMf0Gq1Vu26du2KUaNG4cCBAxg4cCA8PT3RvXt3rFu3zqqdXq/H66+/jp49e8LT0xPBwcEYPHgwdu7caYvfciJqBf7ziYgc3nvvvYdnnnkGvr6+ePXVVwEA4eHhAGrXPQ0dOhSXLl3CrFmz0KVLFxw6dAhpaWm4cuUK3nvvPau+Vq9ejZqaGjz55JNQKBQICgqCWq3Gv/71L0yaNAl//etfUVFRgVWrVuGBBx7AkSNHcOuttyI0NBQrV67E3/72N4wdOxbjxo0DANxyyy1N1j1z5kysXbsWf/7znzFnzhwcPnwYS5cuxalTp5Cenm7V9uzZs/jzn/+MGTNmYNq0afj888+RmpqK2267DUlJSQBqw9vSpUsxc+ZMDBw4EGq1GpmZmcjKysJ9991nq99uImqOSETkgFavXi0CEPPy8kRRFMWkpCRx6NChDdotWrRI9PHxEXNycqyOz507V5TL5WJBQYEoiqKYl5cnAhD9/f3FoqIiq7YGg0HUarVWx65fvy6Gh4eLTzzxhOVYcXGxCEB87bXXGtTx2muvifX/yj1+/LgIQJw5c6ZVuxdffFEEIP7888+WY3FxcSIAcd++fZZjRUVFokKhEOfMmWM51q9fP3HkyJEN3puIOg+nAonIqX377bcYMmQIAgMDUVJSYnkMHz4cRqMR+/bts2o/fvx4y5SemVwut6yzMplMKCsrg8FgwIABA5CVldWuun788UcAwAsvvGB1fM6cOQCAbdu2WR3v06cPhgwZYnkdGhqKXr164fz585ZjAQEBOHHiBHJzc9tVExHdPE4FEpFTy83NxX//+98GYcmsqKjI6nW3bt0abbd27Vq88847OH36NPR6fYvtW3LhwgXIZDL06NHD6nhERAQCAgJw4cIFq+NdunRp0EdgYCCuX79uef3GG2/gkUceQUJCApKTk/Hggw9iypQpzU5HEpFtMVgRkVMzmUy477778PLLLzd6PiEhweq1l5dXgzZffvklUlNTMWbMGLz00ksICwuDXC7H0qVLce7cuZuqr7Wbhjb1DUix3o45d911F86dO4fvv/8eO3bswL/+9S+8++67+PjjjzFz5sybqpOIWofBioicQlMBJT4+HpWVlRg+fHi7+964cSO6d++OzZs3W73Pa6+91qoaGhMXFweTyYTc3Fz07t3bcvzatWsoLy9HXFxcu2oNCgrC9OnTMX36dFRWVuKuu+7CwoULGayIOgnXWBGRU/Dx8UF5eXmD4xMmTMAvv/yCn376qcG58vJyGAyGFvs2jxbVHx06fPgwfvnlF6t23t7eln5bMmLECABo8K3EZcuWAQBGjhzZYh9/VFpaavXa19cXPXr0aLB9AxF1HI5YEZFTuO2227By5UosXrwYPXr0QFhYGO655x689NJL2LJlC0aNGmXZnqCqqgq///47Nm7ciPz8fISEhDTb96hRo7B582aMHTsWI0eORF5eHj7++GP06dMHlZWVlnZeXl7o06cPNmzYgISEBAQFBSE5ORnJyckN+uzXrx+mTZuGTz/9FOXl5Rg6dCiOHDmCtWvXYsyYMRg2bFibfw/69OmDu+++G7fddhuCgoKQmZmJjRs34umnn25zX0TUPgxWROQUFixYgAsXLuCf//wnKioqMHToUNxzzz3w9vbG3r17sWTJEnz77bdYt24d/P39kZCQgNdffx1KpbLFvlNTU3H16lV88skn+Omnn9CnTx98+eWX+PbbbxvcQudf//oXnnnmGTz//PPQ6XR47bXXGg1W5rbdu3fHmjVrkJ6ejoiICKSlpTWYYmytZ599Flu2bMGOHTug1WoRFxeHxYsX46WXXmpXf0TUdrxXIBEREZGNcI0VERERkY0wWBERERHZCIMVERERkY0wWBERERHZCIMVERERkY0wWBERERHZCIMVERERkY0wWBERERHZCIMVERERkY0wWBERERHZCIMVERERkY0wWBERERHZyP8HMBIFqzfQ5zQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print( np.array(mf.train_mse_at_epochs)[:,1] )\n",
    "# mf.plot_learning_curve(validation=True)\n",
    "mf.plot_learning_curve(validation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help = np.zeros((mf.P.shape[0], mf.Q.T.shape[1]))\n",
    "# print(np.shape(help))\n",
    "\n",
    "# for i in range(mf.P.shape[0]):\n",
    "#        for j in range(mf.Q.T.shape[1]):\n",
    "#               for k in range(mf.k):\n",
    "#                      help[i][j] += mf.P[i][k] * mf.Q.T[k][j]\n",
    "\n",
    "# print(help)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.64097652 0.81445084 0.50816506 ... 0.79183397 0.88573296 0.29639769]\n",
      " [0.81819179 1.43911481 0.76782272 ... 0.93953074 0.90698471 0.67049783]\n",
      " [0.46768566 0.83350486 0.72810256 ... 0.88206096 0.83578143 0.90009087]\n",
      " ...\n",
      " [0.02789206 0.87064953 0.01057161 ... 0.42721098 0.3386313  1.09833671]\n",
      " [1.18448325 0.31793441 0.59854647 ... 0.75894204 0.67857728 0.94034587]\n",
      " [0.76909415 0.60740241 0.6678389  ... 0.95757274 0.86713029 0.544421  ]] \n",
      "\n",
      "\n",
      "\n",
      " [[0.88105647 0.32218538 1.03716174 ... 0.25000874 0.40175541 0.07859848]\n",
      " [0.23276371 0.43378731 0.45605363 ... 0.29271171 0.60647119 0.48138692]\n",
      " [0.36089094 0.26952669 0.51511856 ... 0.55837359 1.36594245 0.43949882]\n",
      " ...\n",
      " [0.61211538 0.18337519 0.8626645  ... 0.29695985 0.83776925 0.27549677]\n",
      " [0.18773088 0.94658377 0.81863825 ... 0.38696764 0.19148674 0.58730196]\n",
      " [0.50225012 0.96257021 0.35507013 ... 0.50855224 0.42503991 0.23540146]]\n"
     ]
    }
   ],
   "source": [
    "# help2 = mf.P @ mf.Q.T\n",
    "print(mf.P,\"\\n\\n\\n\\n\", mf.Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1., 1., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 1., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> (array([  0,   0,   0, ..., 609, 609, 609]), array([   0,    1,    2, ..., 9721, 9722, 9723]))\n",
      "[[ 0.85  0.88  0.91 ...  0.    0.    0.  ]\n",
      " [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      " [ 0.   -0.   -0.   ... -0.   -0.    0.  ]\n",
      " ...\n",
      " [ 1.    0.    0.   ...  0.    0.    0.  ]\n",
      " [ 0.99 -0.    0.   ...  0.92  0.92  0.  ]\n",
      " [ 0.    0.    0.   ...  0.    0.    0.  ]] \n",
      "\n",
      "[[ 0.85  0.88  0.91 ...  0.    0.    0.  ]\n",
      " [ 0.59  0.27  0.25 ...  0.01  0.01  0.  ]\n",
      " [ 0.24 -0.25 -0.04 ... -0.02 -0.02  0.  ]\n",
      " ...\n",
      " [ 1.    0.5   0.5  ...  0.01  0.01  0.  ]\n",
      " [ 0.99 -0.03  0.47 ...  0.92  0.92  0.  ]\n",
      " [ 0.    0.    0.   ...  0.    0.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "predictions = mf.P.dot(mf.Q.T)\n",
    "mask = np.zeros_like(train.toarray())\n",
    "print(type(predictions.toarray()), type(train.toarray()), train.toarray().nonzero())\n",
    "mask[train.toarray().nonzero()] = 1\n",
    "\n",
    "# Mask out unknown ratings as 0 for ease of comparison.\n",
    "print(np.round(predictions.toarray() * mask, 2), \"\\n\")\n",
    "print(np.round(predictions.toarray(), 2) )\n",
    "######--------\n",
    "# predictions = mf.P.dot(mf.Q.T)\n",
    "# mask = np.zeros_like(train)\n",
    "# print(type(predictions.toarray()), type(train.toarray()), train.toarray().nonzero())\n",
    "# mask[train.nonzero()] = 1\n",
    "\n",
    "# # Mask out unknown ratings as 0 for ease of comparison.\n",
    "# print(np.round(predictions * mask, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### File saving and download utility for Colab\n",
    "\n",
    "# from google.colab import files\n",
    "\n",
    "# user_emb_df = pd.DataFrame(P)\n",
    "# user_emb_df.to_csv(\"saved_user_emb.csv\", delimiter=\"\\t\", index=True)\n",
    "# movie_emb_df = pd.DataFrame(Q)\n",
    "# movie_emb_df.to_csv(\"saved_movie_emb.csv\", delimiter=\"\\t\", index=True)\n",
    "\n",
    "# files.download(\"saved_user_emb.csv\")\n",
    "# files.download(\"saved_movie_emb.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RecSys_Env",
   "language": "python",
   "name": "recsys_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
